{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.set_default_dtype(torch.float)\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data       = np.load(\"./data/ecg_data.npz\")\n",
    "Xtr        = torch.tensor(data[\"Xtr\"]).type(torch.float).to(device)    #Clean train\n",
    "Xtr_noise  = torch.tensor(data[\"Xtr_noise\"]).type(torch.float).to(device)  #Noisy train\n",
    "Xte_noise  = torch.tensor(data[\"Xte_noise\"]).type(torch.float).to(device)  #Noisy test\n",
    "\n",
    "params = np.load(\"./data/ecg_params.npz\")\n",
    "W = torch.FloatTensor(params[\"W\"]).type(torch.float).to(device)  #Decoder parameters\n",
    "V = torch.FloatTensor(params[\"V\"]).type(torch.float).to(device)  #Encoder parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu_AE(nn.Module):\n",
    "    def __repr__(self):\n",
    "        return {\"model\":\"LinearAE\",\"K\":self.K,\"lr\":self.lr,\"epoch\":self.epochs}\n",
    "    \n",
    "    def __init__(self, dim,K,epoch=1000,lr=0.001):\n",
    "        super(Relu_AE, self).__init__()\n",
    "        self.model=nn.Sequential(\n",
    "            nn.Linear(dim, K),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(K,dim)\n",
    "            )\n",
    "        self.lr=lr\n",
    "        self.epochs=epoch\n",
    "        self.criterion=nn.MSELoss(reduction=\"mean\")\n",
    "        self.K=K\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    def reconstruct(self,x,W,V):\n",
    "        self.model[0].weight.data=W\n",
    "        self.model[1].weight.data=V\n",
    "        x=self.model(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self,X,X_hat):\n",
    "        return self.criterion(X,X_hat).item()\n",
    "    \n",
    "    \n",
    "    def fit(self,X,R):\n",
    "        train_loss_list=[]\n",
    "        optimizer=optim.Adam(self.parameters(),lr=self.lr)\n",
    "        for epoch in range(self.epochs+1):\n",
    "            train_loss = 0.0\n",
    "            self.model.train()\n",
    "            optimizer.zero_grad()\n",
    "            output = self.model(X)\n",
    "            loss = self.criterion(output, R)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_list.append(loss)\n",
    "            #if(epoch%100==0):print('Epoch [{}/{}], Train Loss: {:.9f}'.format(epoch, self.epochs, loss))\n",
    "        #self.saver(self.model.state_dict())\n",
    "        return loss.item()\n",
    "\n",
    "    def test(self,X,R):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            output=self.model(X)\n",
    "            loss=self.criterion(output,R)\n",
    "            return loss\n",
    "\n",
    "    def print_param(self):\n",
    "        for param in self.parameters():\n",
    "            print(f'parameter shape:{param.shape}')\n",
    "            #print(f'parameter value:{param.data}')\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_loss(X,X_hat):\n",
    "        time=len(X)\n",
    "        plt.plot(range(1, time+1), X.cpu().detach().numpy(), label='Noisy Data')\n",
    "        plt.plot(range(1, time+1), X_hat.cpu().detach().numpy(), label='Reconstructed Data')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('ECG')\n",
    "        plt.title('Noisy Data vs. Reconstructed Data')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def saver(self,best_weights,PATH=\"./models\"):\n",
    "        name=''.join(f\"{key}{val}\" for key, val in self.__repr__().items())\n",
    "        path=PATH+\"/\"+name\n",
    "        torch.save(best_weights,path)\n",
    "    \n",
    "    # def dataloader(self,X,R,batch_size=128):\n",
    "    #     dataset = ECGDataset(X,R)\n",
    "    #     dataloader=DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    #     return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1500], Train Loss: 2.675340652\n",
      "Epoch [100/1500], Train Loss: 0.500086784\n",
      "Epoch [200/1500], Train Loss: 0.302896261\n",
      "Epoch [300/1500], Train Loss: 0.231185749\n",
      "Epoch [400/1500], Train Loss: 0.194383904\n",
      "Epoch [500/1500], Train Loss: 0.182105348\n",
      "Epoch [600/1500], Train Loss: 0.168802336\n",
      "Epoch [700/1500], Train Loss: 0.164180547\n",
      "Epoch [800/1500], Train Loss: 0.163829684\n",
      "Epoch [900/1500], Train Loss: 0.155608192\n",
      "Epoch [1000/1500], Train Loss: 0.159630999\n",
      "Epoch [1100/1500], Train Loss: 0.151950091\n",
      "Epoch [1200/1500], Train Loss: 0.152611017\n",
      "Epoch [1300/1500], Train Loss: 0.146961004\n",
      "Epoch [1400/1500], Train Loss: 0.156033874\n",
      "Epoch [1500/1500], Train Loss: 0.144171774\n"
     ]
    }
   ],
   "source": [
    "model=Relu_AE(100,10,lr=0.01,epoch=1500).to(device)\n",
    "loss=model.fit(Xtr,Xtr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K:10 Train Loss:0.3219006359577179   Test Loss:0.32627904415130615\n",
      "K:15 Train Loss:0.19815082848072052   Test Loss:0.20917046070098877\n",
      "K:20 Train Loss:0.15424960851669312   Test Loss:0.1589110642671585\n",
      "K:25 Train Loss:0.12821383774280548   Test Loss:0.11921767145395279\n",
      "K:30 Train Loss:0.10664771497249603   Test Loss:0.10253103822469711\n",
      "K:35 Train Loss:0.09462974965572357   Test Loss:0.10278108716011047\n",
      "K:40 Train Loss:0.08488091826438904   Test Loss:0.09520789980888367\n",
      "K:45 Train Loss:0.07942568510770798   Test Loss:0.09023468941450119\n",
      "K:50 Train Loss:0.07480417937040329   Test Loss:0.08563196659088135\n"
     ]
    }
   ],
   "source": [
    "K=[k for k in range(10,150,5)]\n",
    "train_loss_list=[]\n",
    "test_loss_list=[]\n",
    "best_k=0\n",
    "best_loss=np.inf\n",
    "best_model=None\n",
    "for k in K:\n",
    "    X_train, X_val, R_train, R_val = train_test_split(Xtr_noise, Xtr, test_size=0.2)\n",
    "    model=Relu_AE(100,k,lr=0.001,epoch=1500).to(device)\n",
    "    train_loss=model.fit(X_train,R_train)\n",
    "    train_loss_list.append(train_loss)\n",
    "    test_loss=model.test(X_val,R_val)\n",
    "    test_loss_list.append(test_loss)\n",
    "    if test_loss<best_loss:\n",
    "        best_k=k\n",
    "        best_model=model\n",
    "        best_loss=test_loss\n",
    "    print(f'K:{k} Train Loss:{train_loss}   Test Loss:{test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred=best_model.forward(Xte_noise)\n",
    "for i in range(5):\n",
    "    best_model.plot_loss(Xte_noise[i],X_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
