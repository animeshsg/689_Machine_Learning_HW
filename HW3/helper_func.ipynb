{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArithmeticExpressionDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.Y[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HelperClass:\n",
    "    def __init__(self,X,Y,model,epochs,lr=1e-3):\n",
    "        self.model=model\n",
    "        self.epochs=epochs\n",
    "        self.optimizer=optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.X=X\n",
    "        self.Y=Y\n",
    "        self.criterion=nn.MSELoss()\n",
    "    \n",
    "    @staticmethod\n",
    "    def init_device():\n",
    "        device = torch.device('mps' if torch.backends.mps.is_available() else 'mps')\n",
    "        torch.manual_seed(1)\n",
    "        return device\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_loss(train_loss, val_loss, epochs):\n",
    "        plt.plot(range(1, epochs+1), train_loss, label='Training Loss')\n",
    "        plt.plot(range(1, epochs+1), val_loss, label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    def dataloader(self,X,Y,batch_size=1024):\n",
    "        #X_train, X_val, Y_train, Y_val = train_test_split(Xtr, Ytr, test_size=0.2)\n",
    "        dataset = ArithmeticExpressionDataset(X,Y)\n",
    "        dataloader=DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        return dataloader\n",
    "\n",
    "    def saver(self,best_weights,PATH=\"./models\"):\n",
    "        name=''.join(f\"{key}{val}\" for key, val in self.model.__repr__().items())\n",
    "        path=PATH+\"/\"+name\n",
    "        torch.save(best_weights,path)\n",
    "\n",
    "    def trainer(self):\n",
    "        device=self.init_device()\n",
    "        val_loss_list=[]\n",
    "        train_loss_list=[]\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(self.X, self.Y, test_size=0.2)\n",
    "        train_loader=self.dataloader(X_train,Y_train)\n",
    "        val_loader=self.dataloader(X_val,Y_val)\n",
    "        best_valid_loss = float(\"inf\")\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss = 0.0\n",
    "            val_loss = 0.0\n",
    "            self.model.train()\n",
    "            for x, y in train_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(x)\n",
    "                loss = self.criterion(output, y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_loss += loss.item() * x.size(0)\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "            train_loss_list.append(train_loss)\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                for x, y in val_loader:\n",
    "                    x = x.to(device)\n",
    "                    y = y.to(device)\n",
    "                    output = self.model(x)\n",
    "                    loss = self.criterion(output, y)\n",
    "                    val_loss += loss.item() * x.size(0)\n",
    "                val_loss /= len(val_loader.dataset)\n",
    "                val_loss_list.append(val_loss)\n",
    "                if val_loss < best_valid_loss:\n",
    "                    best_valid_loss=val_loss\n",
    "                    best_weights = copy.deepcopy(self.model.state_dict())\n",
    "            print('Epoch [{}/{}], Train Loss: {:.4f}, Val Loss: {:.4f}'.format(epoch+1, self.epochs, train_loss, val_loss))\n",
    "        self.plot_loss(train_loss_list,val_loss_list,self.epochs)\n",
    "        self.saver(best_weights)\n",
    "        return best_valid_loss\n",
    "    \n",
    "    def tester(self,X,Y):\n",
    "        device=self.init_device()\n",
    "        name=''.join(f\"{key}{val}\" for key, val in self.model.__repr__().items())\n",
    "        path=\"./models/\"+name\n",
    "        self.model.load_state_dict(torch.load(path))\n",
    "        test_loader=self.dataloader(X,Y)\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                output = self.model(x)\n",
    "                loss = self.criterion(output, y)\n",
    "                test_loss += loss.item()*x.size(0)\n",
    "            test_loss /= len(test_loader.dataset)\n",
    "            print('Test Loss: {:.6f}'.format(test_loss))\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __repr__(self):\n",
    "        return {\"model\":\"RNN\",\"ES\":self.embedding_size,\"HS\":self.hidden_size}\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, embedding_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "        #Model Arch\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, batch_first=True,nonlinearity=\"relu\")\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "torch.manual_seed(1)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"./data/ae_data.npz\")\n",
    "\n",
    "Str = data[\"Str\"]\n",
    "Xtr = torch.from_numpy(data[\"Xtr\"]).type(torch.int)\n",
    "Ytr = torch.from_numpy(data[\"Ytr\"]).type(torch.float)\n",
    "\n",
    "Ste = data[\"Ste\"]\n",
    "Xte = torch.from_numpy(data[\"Xte\"]).type(torch.int)\n",
    "Yte = torch.from_numpy(data[\"Yte\"]).type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "batch_size = 1024\n",
    "learning_rate = 1e-4\n",
    "hidden_size = 64\n",
    "num_layers = 4\n",
    "embedding_size=16\n",
    "model = RNNModel(input_size=13, hidden_size=hidden_size, num_layers=num_layers, output_size=1,embedding_size=embedding_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn=HelperClass(Xtr,Ytr,model,num_epochs,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __repr__(self):\n",
    "        return {\"model\":\"Transformer\",\"DM\":self.d_model,\"NH\":self.nhead,\"NL\":self.num_layers}\n",
    "    \n",
    "    \n",
    "    def __init__(self, input_dim, d_model, nhead, num_layers, output_dim):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.d_model=d_model\n",
    "        self.nhead=nhead\n",
    "        self.num_layers=num_layers\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(input_dim, d_model)\n",
    "\n",
    "        # Transformer model\n",
    "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_layers,\n",
    "                                          num_decoder_layers=num_layers)\n",
    "\n",
    "        # Linear output layer\n",
    "        self.output = nn.Linear(d_model, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Prepare the input tensor for the transformer model\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        # Forward propagate transformer model\n",
    "        out = self.transformer(x, x)\n",
    "\n",
    "        # Decode the output of the transformer model\n",
    "        out = self.output(out[-1, :, :])\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vocab_size=1\n",
    "num_features=13\n",
    "d_model=64\n",
    "nhead=4\n",
    "num_layers=4\n",
    "model = TransformerModel(num_features,d_model,nhead,num_layers,output_vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans=HelperClass(Xtr,Ytr,model,num_epochs,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __repr__(self):\n",
    "        return {\"model\":\"MLP\",\"FL\":self.input_dim,\"HL\":self.hidden_dim}\n",
    "    \n",
    "    def __init__(self, input_dimension, hidden_dimension, output_dimension):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.input_dim = input_dimension\n",
    "        self.hidden_dim = hidden_dimension\n",
    "        self.output_dim = output_dimension\n",
    "        self.layers=nn.Sequential(\n",
    "            nn.Linear(input_dimension, hidden_dimension),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dimension, hidden_dimension),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dimension, output_dimension)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.to(torch.float32)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPModel(7, 512, 1).to(torch.device(\"mps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp=HelperClass(Xtr,Ytr,model,1000,torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Train Loss: 175367.1403, Val Loss: 147450.6169\n",
      "Epoch [2/1000], Train Loss: 128124.7341, Val Loss: 120034.8819\n",
      "Epoch [3/1000], Train Loss: 113241.4988, Val Loss: 114014.2295\n",
      "Epoch [4/1000], Train Loss: 109870.1180, Val Loss: 111857.8111\n",
      "Epoch [5/1000], Train Loss: 107892.0471, Val Loss: 109866.1818\n",
      "Epoch [6/1000], Train Loss: 106462.4312, Val Loss: 109387.2518\n",
      "Epoch [7/1000], Train Loss: 105335.0437, Val Loss: 107388.5142\n",
      "Epoch [8/1000], Train Loss: 104112.9704, Val Loss: 106406.4295\n",
      "Epoch [9/1000], Train Loss: 102933.0935, Val Loss: 105067.3419\n",
      "Epoch [10/1000], Train Loss: 101829.8720, Val Loss: 104580.5915\n",
      "Epoch [11/1000], Train Loss: 100670.2126, Val Loss: 102764.6740\n",
      "Epoch [12/1000], Train Loss: 99282.4828, Val Loss: 102078.3423\n",
      "Epoch [13/1000], Train Loss: 97692.6617, Val Loss: 99994.7327\n",
      "Epoch [14/1000], Train Loss: 96150.9796, Val Loss: 98667.3356\n",
      "Epoch [15/1000], Train Loss: 94672.6552, Val Loss: 95948.4840\n",
      "Epoch [16/1000], Train Loss: 92523.5482, Val Loss: 94257.4393\n",
      "Epoch [17/1000], Train Loss: 90001.2023, Val Loss: 90880.8031\n",
      "Epoch [18/1000], Train Loss: 87358.7859, Val Loss: 88033.4579\n",
      "Epoch [19/1000], Train Loss: 83377.9052, Val Loss: 86588.9437\n",
      "Epoch [20/1000], Train Loss: 79315.3824, Val Loss: 78848.4829\n",
      "Epoch [21/1000], Train Loss: 74309.4176, Val Loss: 73362.1801\n",
      "Epoch [22/1000], Train Loss: 68512.2026, Val Loss: 67885.1673\n",
      "Epoch [23/1000], Train Loss: 62195.9001, Val Loss: 67136.2374\n",
      "Epoch [24/1000], Train Loss: 59313.3748, Val Loss: 55812.9627\n",
      "Epoch [25/1000], Train Loss: 52162.8919, Val Loss: 50875.7591\n",
      "Epoch [26/1000], Train Loss: 46827.3824, Val Loss: 45349.9369\n",
      "Epoch [27/1000], Train Loss: 41241.9000, Val Loss: 41677.0096\n",
      "Epoch [28/1000], Train Loss: 38124.5362, Val Loss: 36579.7122\n",
      "Epoch [29/1000], Train Loss: 33259.5634, Val Loss: 32012.9983\n",
      "Epoch [30/1000], Train Loss: 29323.6810, Val Loss: 28295.1935\n",
      "Epoch [31/1000], Train Loss: 26354.9417, Val Loss: 25239.7845\n",
      "Epoch [32/1000], Train Loss: 23311.6348, Val Loss: 22158.8858\n",
      "Epoch [33/1000], Train Loss: 20330.6265, Val Loss: 19635.1342\n",
      "Epoch [34/1000], Train Loss: 17875.9003, Val Loss: 17572.4603\n",
      "Epoch [35/1000], Train Loss: 15702.9095, Val Loss: 15720.6684\n",
      "Epoch [36/1000], Train Loss: 15389.2206, Val Loss: 22493.2731\n",
      "Epoch [37/1000], Train Loss: 12784.3833, Val Loss: 12551.1326\n",
      "Epoch [38/1000], Train Loss: 11411.8128, Val Loss: 11063.2807\n",
      "Epoch [39/1000], Train Loss: 10075.9946, Val Loss: 10021.5628\n",
      "Epoch [40/1000], Train Loss: 9341.1322, Val Loss: 9798.0042\n",
      "Epoch [41/1000], Train Loss: 8314.2294, Val Loss: 8306.1427\n",
      "Epoch [42/1000], Train Loss: 7808.7790, Val Loss: 7619.3804\n",
      "Epoch [43/1000], Train Loss: 7317.1943, Val Loss: 7150.1574\n",
      "Epoch [44/1000], Train Loss: 6490.3185, Val Loss: 6593.4921\n",
      "Epoch [45/1000], Train Loss: 6254.6711, Val Loss: 6304.7134\n",
      "Epoch [46/1000], Train Loss: 5672.4267, Val Loss: 5673.7266\n",
      "Epoch [47/1000], Train Loss: 5274.4481, Val Loss: 6657.2521\n",
      "Epoch [48/1000], Train Loss: 5193.0614, Val Loss: 5030.8101\n",
      "Epoch [49/1000], Train Loss: 4699.0353, Val Loss: 4969.7793\n",
      "Epoch [50/1000], Train Loss: 4871.8777, Val Loss: 4693.1619\n",
      "Epoch [51/1000], Train Loss: 4128.1113, Val Loss: 4659.2715\n",
      "Epoch [52/1000], Train Loss: 3956.9340, Val Loss: 4175.6789\n",
      "Epoch [53/1000], Train Loss: 3863.1100, Val Loss: 5060.0389\n",
      "Epoch [54/1000], Train Loss: 3526.9928, Val Loss: 3477.1489\n",
      "Epoch [55/1000], Train Loss: 3242.5801, Val Loss: 4124.1527\n",
      "Epoch [56/1000], Train Loss: 3323.4161, Val Loss: 3568.8889\n",
      "Epoch [57/1000], Train Loss: 3253.4031, Val Loss: 3596.4599\n",
      "Epoch [58/1000], Train Loss: 2851.0909, Val Loss: 3040.6899\n",
      "Epoch [59/1000], Train Loss: 2754.9604, Val Loss: 2757.1818\n",
      "Epoch [60/1000], Train Loss: 2617.5861, Val Loss: 2696.9460\n",
      "Epoch [61/1000], Train Loss: 2468.2985, Val Loss: 2520.7049\n",
      "Epoch [62/1000], Train Loss: 2355.7020, Val Loss: 2461.1005\n",
      "Epoch [63/1000], Train Loss: 2338.4449, Val Loss: 2468.0510\n",
      "Epoch [64/1000], Train Loss: 2247.4411, Val Loss: 2269.1145\n",
      "Epoch [65/1000], Train Loss: 2300.1160, Val Loss: 2109.1110\n",
      "Epoch [66/1000], Train Loss: 2298.8957, Val Loss: 2376.8971\n",
      "Epoch [67/1000], Train Loss: 2082.4716, Val Loss: 2243.0223\n",
      "Epoch [68/1000], Train Loss: 1901.6917, Val Loss: 1914.1732\n",
      "Epoch [69/1000], Train Loss: 1874.6673, Val Loss: 1924.5238\n",
      "Epoch [70/1000], Train Loss: 2026.0574, Val Loss: 1787.4482\n",
      "Epoch [71/1000], Train Loss: 1823.7900, Val Loss: 2310.4582\n",
      "Epoch [72/1000], Train Loss: 1810.5977, Val Loss: 1923.2100\n",
      "Epoch [73/1000], Train Loss: 1712.3691, Val Loss: 1786.1393\n",
      "Epoch [74/1000], Train Loss: 1586.8677, Val Loss: 1576.8893\n",
      "Epoch [75/1000], Train Loss: 1610.5832, Val Loss: 2011.3172\n",
      "Epoch [76/1000], Train Loss: 1498.0505, Val Loss: 1513.0481\n",
      "Epoch [77/1000], Train Loss: 2829.0444, Val Loss: 1472.6056\n",
      "Epoch [78/1000], Train Loss: 1379.2354, Val Loss: 1533.4593\n",
      "Epoch [79/1000], Train Loss: 1366.8059, Val Loss: 1879.9669\n",
      "Epoch [80/1000], Train Loss: 1378.2186, Val Loss: 1446.3721\n",
      "Epoch [81/1000], Train Loss: 1310.4370, Val Loss: 1643.7705\n",
      "Epoch [82/1000], Train Loss: 1428.4234, Val Loss: 1298.6456\n",
      "Epoch [83/1000], Train Loss: 1374.4775, Val Loss: 1293.4104\n",
      "Epoch [84/1000], Train Loss: 1389.7106, Val Loss: 1675.9389\n",
      "Epoch [85/1000], Train Loss: 1220.7704, Val Loss: 1170.1924\n",
      "Epoch [86/1000], Train Loss: 2030.6656, Val Loss: 1166.9912\n",
      "Epoch [87/1000], Train Loss: 1250.5043, Val Loss: 1129.7101\n",
      "Epoch [88/1000], Train Loss: 1073.7318, Val Loss: 1141.9043\n",
      "Epoch [89/1000], Train Loss: 1101.7526, Val Loss: 1079.4110\n",
      "Epoch [90/1000], Train Loss: 1063.5550, Val Loss: 1107.3121\n",
      "Epoch [91/1000], Train Loss: 1060.7224, Val Loss: 1026.2783\n",
      "Epoch [92/1000], Train Loss: 1045.0270, Val Loss: 1281.6709\n",
      "Epoch [93/1000], Train Loss: 1188.7052, Val Loss: 1020.5165\n",
      "Epoch [94/1000], Train Loss: 1003.9397, Val Loss: 1001.9296\n",
      "Epoch [95/1000], Train Loss: 1767.8462, Val Loss: 1169.3916\n",
      "Epoch [96/1000], Train Loss: 975.1848, Val Loss: 950.7854\n",
      "Epoch [97/1000], Train Loss: 974.1986, Val Loss: 908.4788\n",
      "Epoch [98/1000], Train Loss: 920.0232, Val Loss: 1033.9043\n",
      "Epoch [99/1000], Train Loss: 932.1370, Val Loss: 903.0846\n",
      "Epoch [100/1000], Train Loss: 1409.0842, Val Loss: 1030.3353\n",
      "Epoch [101/1000], Train Loss: 1129.3247, Val Loss: 864.7204\n",
      "Epoch [102/1000], Train Loss: 884.0342, Val Loss: 905.2050\n",
      "Epoch [103/1000], Train Loss: 919.7910, Val Loss: 815.8985\n",
      "Epoch [104/1000], Train Loss: 840.3197, Val Loss: 834.7876\n",
      "Epoch [105/1000], Train Loss: 829.7321, Val Loss: 813.5878\n",
      "Epoch [106/1000], Train Loss: 932.2645, Val Loss: 781.3869\n",
      "Epoch [107/1000], Train Loss: 2268.8098, Val Loss: 1373.7049\n",
      "Epoch [108/1000], Train Loss: 807.9960, Val Loss: 879.9755\n",
      "Epoch [109/1000], Train Loss: 750.7270, Val Loss: 787.6499\n",
      "Epoch [110/1000], Train Loss: 762.0430, Val Loss: 776.5611\n",
      "Epoch [111/1000], Train Loss: 770.5955, Val Loss: 853.2563\n",
      "Epoch [112/1000], Train Loss: 730.3029, Val Loss: 727.9904\n",
      "Epoch [113/1000], Train Loss: 703.4818, Val Loss: 781.4545\n",
      "Epoch [114/1000], Train Loss: 785.6616, Val Loss: 693.6313\n",
      "Epoch [115/1000], Train Loss: 762.2634, Val Loss: 735.1223\n",
      "Epoch [116/1000], Train Loss: 689.9915, Val Loss: 732.3651\n",
      "Epoch [117/1000], Train Loss: 742.6598, Val Loss: 882.9134\n",
      "Epoch [118/1000], Train Loss: 1458.6888, Val Loss: 1092.4208\n",
      "Epoch [119/1000], Train Loss: 1580.1605, Val Loss: 993.8842\n",
      "Epoch [120/1000], Train Loss: 652.4570, Val Loss: 696.8281\n",
      "Epoch [121/1000], Train Loss: 638.6219, Val Loss: 639.7726\n",
      "Epoch [122/1000], Train Loss: 618.0594, Val Loss: 658.2641\n",
      "Epoch [123/1000], Train Loss: 607.0181, Val Loss: 733.5158\n",
      "Epoch [124/1000], Train Loss: 620.6471, Val Loss: 634.8008\n",
      "Epoch [125/1000], Train Loss: 614.2383, Val Loss: 869.2386\n",
      "Epoch [126/1000], Train Loss: 864.2999, Val Loss: 988.6874\n",
      "Epoch [127/1000], Train Loss: 631.8851, Val Loss: 615.2533\n",
      "Epoch [128/1000], Train Loss: 607.6564, Val Loss: 609.4061\n",
      "Epoch [129/1000], Train Loss: 579.2085, Val Loss: 598.5578\n",
      "Epoch [130/1000], Train Loss: 692.3027, Val Loss: 570.9313\n",
      "Epoch [131/1000], Train Loss: 830.4186, Val Loss: 573.7472\n",
      "Epoch [132/1000], Train Loss: 757.4849, Val Loss: 582.5483\n",
      "Epoch [133/1000], Train Loss: 666.1933, Val Loss: 1130.0943\n",
      "Epoch [134/1000], Train Loss: 671.8844, Val Loss: 668.4148\n",
      "Epoch [135/1000], Train Loss: 597.6009, Val Loss: 742.1225\n",
      "Epoch [136/1000], Train Loss: 592.2760, Val Loss: 531.3933\n",
      "Epoch [137/1000], Train Loss: 636.4297, Val Loss: 530.9161\n",
      "Epoch [138/1000], Train Loss: 644.7991, Val Loss: 1103.3010\n",
      "Epoch [139/1000], Train Loss: 697.8337, Val Loss: 526.7584\n",
      "Epoch [140/1000], Train Loss: 529.0863, Val Loss: 582.4471\n",
      "Epoch [141/1000], Train Loss: 611.7857, Val Loss: 712.3393\n",
      "Epoch [142/1000], Train Loss: 623.7084, Val Loss: 1365.3356\n",
      "Epoch [143/1000], Train Loss: 606.5995, Val Loss: 521.7610\n",
      "Epoch [144/1000], Train Loss: 513.2279, Val Loss: 847.7814\n",
      "Epoch [145/1000], Train Loss: 989.4885, Val Loss: 1123.3820\n",
      "Epoch [146/1000], Train Loss: 586.5430, Val Loss: 607.2880\n",
      "Epoch [147/1000], Train Loss: 547.8682, Val Loss: 817.8801\n",
      "Epoch [148/1000], Train Loss: 568.5671, Val Loss: 701.0192\n",
      "Epoch [149/1000], Train Loss: 504.5284, Val Loss: 730.1527\n",
      "Epoch [150/1000], Train Loss: 538.1713, Val Loss: 538.9283\n",
      "Epoch [151/1000], Train Loss: 845.8934, Val Loss: 652.7632\n",
      "Epoch [152/1000], Train Loss: 626.6786, Val Loss: 450.1157\n",
      "Epoch [153/1000], Train Loss: 503.3594, Val Loss: 447.4858\n",
      "Epoch [154/1000], Train Loss: 524.4463, Val Loss: 571.4579\n",
      "Epoch [155/1000], Train Loss: 489.8508, Val Loss: 580.2831\n",
      "Epoch [156/1000], Train Loss: 480.6305, Val Loss: 850.6541\n",
      "Epoch [157/1000], Train Loss: 668.8685, Val Loss: 1015.2601\n",
      "Epoch [158/1000], Train Loss: 622.4103, Val Loss: 885.2040\n",
      "Epoch [159/1000], Train Loss: 692.6450, Val Loss: 454.3290\n",
      "Epoch [160/1000], Train Loss: 419.6463, Val Loss: 436.4346\n",
      "Epoch [161/1000], Train Loss: 717.0886, Val Loss: 660.5074\n",
      "Epoch [162/1000], Train Loss: 604.1386, Val Loss: 2310.6767\n",
      "Epoch [163/1000], Train Loss: 3409.0211, Val Loss: 597.7290\n",
      "Epoch [164/1000], Train Loss: 467.8129, Val Loss: 422.3279\n",
      "Epoch [165/1000], Train Loss: 387.7832, Val Loss: 429.5479\n",
      "Epoch [166/1000], Train Loss: 398.2405, Val Loss: 402.5948\n",
      "Epoch [167/1000], Train Loss: 381.3491, Val Loss: 451.2652\n",
      "Epoch [168/1000], Train Loss: 432.7714, Val Loss: 559.4655\n",
      "Epoch [169/1000], Train Loss: 383.0279, Val Loss: 434.5026\n",
      "Epoch [170/1000], Train Loss: 366.0202, Val Loss: 385.2478\n",
      "Epoch [171/1000], Train Loss: 380.0998, Val Loss: 383.6247\n",
      "Epoch [172/1000], Train Loss: 387.5234, Val Loss: 438.4002\n",
      "Epoch [173/1000], Train Loss: 393.1416, Val Loss: 440.1774\n",
      "Epoch [174/1000], Train Loss: 394.3622, Val Loss: 538.6683\n",
      "Epoch [175/1000], Train Loss: 379.3355, Val Loss: 391.1786\n",
      "Epoch [176/1000], Train Loss: 417.4272, Val Loss: 414.7081\n",
      "Epoch [177/1000], Train Loss: 441.5198, Val Loss: 366.5312\n",
      "Epoch [178/1000], Train Loss: 680.0953, Val Loss: 418.1994\n",
      "Epoch [179/1000], Train Loss: 394.4758, Val Loss: 350.2643\n",
      "Epoch [180/1000], Train Loss: 498.3316, Val Loss: 402.7819\n",
      "Epoch [181/1000], Train Loss: 533.8540, Val Loss: 521.6019\n",
      "Epoch [182/1000], Train Loss: 358.3387, Val Loss: 476.1285\n",
      "Epoch [183/1000], Train Loss: 395.7064, Val Loss: 396.0873\n",
      "Epoch [184/1000], Train Loss: 348.6588, Val Loss: 436.5294\n",
      "Epoch [185/1000], Train Loss: 351.4483, Val Loss: 337.6872\n",
      "Epoch [186/1000], Train Loss: 382.2271, Val Loss: 364.4113\n",
      "Epoch [187/1000], Train Loss: 997.2256, Val Loss: 454.9515\n",
      "Epoch [188/1000], Train Loss: 422.7012, Val Loss: 813.3881\n",
      "Epoch [189/1000], Train Loss: 428.3204, Val Loss: 320.2145\n",
      "Epoch [190/1000], Train Loss: 314.6050, Val Loss: 372.5307\n",
      "Epoch [191/1000], Train Loss: 437.4328, Val Loss: 1400.3839\n",
      "Epoch [192/1000], Train Loss: 661.3693, Val Loss: 341.8249\n",
      "Epoch [193/1000], Train Loss: 328.4515, Val Loss: 414.4105\n",
      "Epoch [194/1000], Train Loss: 487.2017, Val Loss: 339.9437\n",
      "Epoch [195/1000], Train Loss: 376.9006, Val Loss: 832.0575\n",
      "Epoch [196/1000], Train Loss: 404.8064, Val Loss: 431.0303\n",
      "Epoch [197/1000], Train Loss: 344.0984, Val Loss: 512.8118\n",
      "Epoch [198/1000], Train Loss: 579.4266, Val Loss: 339.0446\n",
      "Epoch [199/1000], Train Loss: 346.3049, Val Loss: 300.7825\n",
      "Epoch [200/1000], Train Loss: 406.2972, Val Loss: 763.2896\n",
      "Epoch [201/1000], Train Loss: 554.1759, Val Loss: 404.0667\n",
      "Epoch [202/1000], Train Loss: 479.7446, Val Loss: 727.4857\n",
      "Epoch [203/1000], Train Loss: 328.5771, Val Loss: 1658.7560\n",
      "Epoch [204/1000], Train Loss: 415.2635, Val Loss: 336.0026\n",
      "Epoch [205/1000], Train Loss: 342.8398, Val Loss: 376.3830\n",
      "Epoch [206/1000], Train Loss: 332.3372, Val Loss: 288.6458\n",
      "Epoch [207/1000], Train Loss: 646.7752, Val Loss: 1085.6856\n",
      "Epoch [208/1000], Train Loss: 460.9470, Val Loss: 291.9570\n",
      "Epoch [209/1000], Train Loss: 297.1293, Val Loss: 434.5749\n",
      "Epoch [210/1000], Train Loss: 370.5530, Val Loss: 307.4800\n",
      "Epoch [211/1000], Train Loss: 395.1613, Val Loss: 897.0108\n",
      "Epoch [212/1000], Train Loss: 1005.0711, Val Loss: 1352.3839\n",
      "Epoch [213/1000], Train Loss: 561.5989, Val Loss: 294.1825\n",
      "Epoch [214/1000], Train Loss: 268.1577, Val Loss: 271.1627\n",
      "Epoch [215/1000], Train Loss: 322.7125, Val Loss: 275.9471\n",
      "Epoch [216/1000], Train Loss: 290.9490, Val Loss: 332.7206\n",
      "Epoch [217/1000], Train Loss: 288.0985, Val Loss: 269.1942\n",
      "Epoch [218/1000], Train Loss: 293.4045, Val Loss: 629.8954\n",
      "Epoch [219/1000], Train Loss: 323.3189, Val Loss: 279.8407\n",
      "Epoch [220/1000], Train Loss: 268.1600, Val Loss: 267.0621\n",
      "Epoch [221/1000], Train Loss: 299.6520, Val Loss: 263.6896\n",
      "Epoch [222/1000], Train Loss: 399.1356, Val Loss: 473.5019\n",
      "Epoch [223/1000], Train Loss: 486.1998, Val Loss: 275.0993\n",
      "Epoch [224/1000], Train Loss: 275.5313, Val Loss: 1440.1889\n",
      "Epoch [225/1000], Train Loss: 735.2549, Val Loss: 364.5795\n",
      "Epoch [226/1000], Train Loss: 289.7602, Val Loss: 259.3980\n",
      "Epoch [227/1000], Train Loss: 616.2849, Val Loss: 308.4896\n",
      "Epoch [228/1000], Train Loss: 4580.2471, Val Loss: 609.0875\n",
      "Epoch [229/1000], Train Loss: 272.9519, Val Loss: 248.4777\n",
      "Epoch [230/1000], Train Loss: 233.5057, Val Loss: 354.3566\n",
      "Epoch [231/1000], Train Loss: 231.1412, Val Loss: 267.2683\n",
      "Epoch [232/1000], Train Loss: 222.4501, Val Loss: 232.3928\n",
      "Epoch [233/1000], Train Loss: 234.3435, Val Loss: 239.6460\n",
      "Epoch [234/1000], Train Loss: 233.6591, Val Loss: 233.4200\n",
      "Epoch [235/1000], Train Loss: 212.4406, Val Loss: 255.4884\n",
      "Epoch [236/1000], Train Loss: 230.0175, Val Loss: 226.9023\n",
      "Epoch [237/1000], Train Loss: 236.0279, Val Loss: 232.5928\n",
      "Epoch [238/1000], Train Loss: 241.7617, Val Loss: 260.9315\n",
      "Epoch [239/1000], Train Loss: 210.6999, Val Loss: 281.3442\n",
      "Epoch [240/1000], Train Loss: 263.1757, Val Loss: 227.4697\n",
      "Epoch [241/1000], Train Loss: 211.8788, Val Loss: 268.7879\n",
      "Epoch [242/1000], Train Loss: 223.3556, Val Loss: 264.2361\n",
      "Epoch [243/1000], Train Loss: 370.4624, Val Loss: 233.6850\n",
      "Epoch [244/1000], Train Loss: 242.1963, Val Loss: 342.9242\n",
      "Epoch [245/1000], Train Loss: 229.7205, Val Loss: 215.2936\n",
      "Epoch [246/1000], Train Loss: 221.4553, Val Loss: 237.1894\n",
      "Epoch [247/1000], Train Loss: 342.4887, Val Loss: 231.9530\n",
      "Epoch [248/1000], Train Loss: 232.8607, Val Loss: 288.8670\n",
      "Epoch [249/1000], Train Loss: 279.2503, Val Loss: 259.7855\n",
      "Epoch [250/1000], Train Loss: 230.0468, Val Loss: 217.7165\n",
      "Epoch [251/1000], Train Loss: 317.0740, Val Loss: 282.9361\n",
      "Epoch [252/1000], Train Loss: 684.7782, Val Loss: 4530.6751\n",
      "Epoch [253/1000], Train Loss: 3684.9683, Val Loss: 286.8038\n",
      "Epoch [254/1000], Train Loss: 213.1610, Val Loss: 212.4052\n",
      "Epoch [255/1000], Train Loss: 192.5219, Val Loss: 321.1522\n",
      "Epoch [256/1000], Train Loss: 193.0157, Val Loss: 247.3674\n",
      "Epoch [257/1000], Train Loss: 187.4396, Val Loss: 209.9841\n",
      "Epoch [258/1000], Train Loss: 180.2431, Val Loss: 215.4133\n",
      "Epoch [259/1000], Train Loss: 184.7024, Val Loss: 260.8239\n",
      "Epoch [260/1000], Train Loss: 196.4611, Val Loss: 229.7990\n",
      "Epoch [261/1000], Train Loss: 182.6221, Val Loss: 203.0064\n",
      "Epoch [262/1000], Train Loss: 190.0938, Val Loss: 194.7366\n",
      "Epoch [263/1000], Train Loss: 179.5743, Val Loss: 190.1640\n",
      "Epoch [264/1000], Train Loss: 195.0114, Val Loss: 260.5959\n",
      "Epoch [265/1000], Train Loss: 204.3369, Val Loss: 194.4293\n",
      "Epoch [266/1000], Train Loss: 183.7917, Val Loss: 197.2114\n",
      "Epoch [267/1000], Train Loss: 197.9225, Val Loss: 205.6589\n",
      "Epoch [268/1000], Train Loss: 208.0122, Val Loss: 203.4397\n",
      "Epoch [269/1000], Train Loss: 543.2151, Val Loss: 1511.1188\n",
      "Epoch [270/1000], Train Loss: 457.6967, Val Loss: 471.2853\n",
      "Epoch [271/1000], Train Loss: 195.0111, Val Loss: 262.5852\n",
      "Epoch [272/1000], Train Loss: 212.3201, Val Loss: 186.4385\n",
      "Epoch [273/1000], Train Loss: 179.7291, Val Loss: 238.1312\n",
      "Epoch [274/1000], Train Loss: 281.9406, Val Loss: 567.3453\n",
      "Epoch [275/1000], Train Loss: 199.8887, Val Loss: 205.4862\n",
      "Epoch [276/1000], Train Loss: 178.0577, Val Loss: 196.2932\n",
      "Epoch [277/1000], Train Loss: 2939.1330, Val Loss: 8723.0189\n",
      "Epoch [278/1000], Train Loss: 2149.8344, Val Loss: 206.6387\n",
      "Epoch [279/1000], Train Loss: 171.9147, Val Loss: 192.8511\n",
      "Epoch [280/1000], Train Loss: 159.5254, Val Loss: 179.6268\n",
      "Epoch [281/1000], Train Loss: 163.2013, Val Loss: 195.2220\n",
      "Epoch [282/1000], Train Loss: 165.5496, Val Loss: 175.8241\n",
      "Epoch [283/1000], Train Loss: 152.6729, Val Loss: 173.2141\n",
      "Epoch [284/1000], Train Loss: 157.1923, Val Loss: 188.8435\n",
      "Epoch [285/1000], Train Loss: 159.1230, Val Loss: 226.6639\n",
      "Epoch [286/1000], Train Loss: 159.2444, Val Loss: 170.4975\n",
      "Epoch [287/1000], Train Loss: 168.3587, Val Loss: 170.1242\n",
      "Epoch [288/1000], Train Loss: 157.6677, Val Loss: 230.8034\n",
      "Epoch [289/1000], Train Loss: 170.4672, Val Loss: 167.5718\n",
      "Epoch [290/1000], Train Loss: 155.1709, Val Loss: 208.2853\n",
      "Epoch [291/1000], Train Loss: 159.6246, Val Loss: 163.4751\n",
      "Epoch [292/1000], Train Loss: 168.5559, Val Loss: 169.0687\n",
      "Epoch [293/1000], Train Loss: 167.1612, Val Loss: 180.9159\n",
      "Epoch [294/1000], Train Loss: 164.6476, Val Loss: 204.3112\n",
      "Epoch [295/1000], Train Loss: 190.5580, Val Loss: 200.0351\n",
      "Epoch [296/1000], Train Loss: 361.9243, Val Loss: 233.1664\n",
      "Epoch [297/1000], Train Loss: 181.7993, Val Loss: 170.8291\n",
      "Epoch [298/1000], Train Loss: 219.4660, Val Loss: 292.2604\n",
      "Epoch [299/1000], Train Loss: 203.3858, Val Loss: 243.1896\n",
      "Epoch [300/1000], Train Loss: 160.9154, Val Loss: 205.5391\n",
      "Epoch [301/1000], Train Loss: 533.0591, Val Loss: 178.9021\n",
      "Epoch [302/1000], Train Loss: 159.4597, Val Loss: 155.1256\n",
      "Epoch [303/1000], Train Loss: 154.7500, Val Loss: 199.1747\n",
      "Epoch [304/1000], Train Loss: 250.6062, Val Loss: 159.4837\n",
      "Epoch [305/1000], Train Loss: 172.1249, Val Loss: 313.0392\n",
      "Epoch [306/1000], Train Loss: 970.1888, Val Loss: 707.0956\n",
      "Epoch [307/1000], Train Loss: 203.9390, Val Loss: 169.4419\n",
      "Epoch [308/1000], Train Loss: 180.6533, Val Loss: 165.8098\n",
      "Epoch [309/1000], Train Loss: 148.2075, Val Loss: 295.5791\n",
      "Epoch [310/1000], Train Loss: 228.5706, Val Loss: 454.9348\n",
      "Epoch [311/1000], Train Loss: 180.0106, Val Loss: 224.8157\n",
      "Epoch [312/1000], Train Loss: 504.9519, Val Loss: 175.0547\n",
      "Epoch [313/1000], Train Loss: 403.5839, Val Loss: 758.5477\n",
      "Epoch [314/1000], Train Loss: 2256.1977, Val Loss: 432.8558\n",
      "Epoch [315/1000], Train Loss: 182.2459, Val Loss: 149.5465\n",
      "Epoch [316/1000], Train Loss: 130.7331, Val Loss: 157.3513\n",
      "Epoch [317/1000], Train Loss: 128.2419, Val Loss: 160.2105\n",
      "Epoch [318/1000], Train Loss: 131.7320, Val Loss: 139.7969\n",
      "Epoch [319/1000], Train Loss: 125.7342, Val Loss: 142.7529\n",
      "Epoch [320/1000], Train Loss: 124.6915, Val Loss: 146.6630\n",
      "Epoch [321/1000], Train Loss: 144.1507, Val Loss: 144.9286\n",
      "Epoch [322/1000], Train Loss: 151.4064, Val Loss: 160.7224\n",
      "Epoch [323/1000], Train Loss: 130.8656, Val Loss: 140.6079\n",
      "Epoch [324/1000], Train Loss: 135.2353, Val Loss: 135.3041\n",
      "Epoch [325/1000], Train Loss: 153.2624, Val Loss: 153.2001\n",
      "Epoch [326/1000], Train Loss: 139.9313, Val Loss: 163.5437\n",
      "Epoch [327/1000], Train Loss: 317.8240, Val Loss: 342.5246\n",
      "Epoch [328/1000], Train Loss: 369.4840, Val Loss: 228.5726\n",
      "Epoch [329/1000], Train Loss: 145.3250, Val Loss: 179.8168\n",
      "Epoch [330/1000], Train Loss: 144.5016, Val Loss: 165.6880\n",
      "Epoch [331/1000], Train Loss: 165.9281, Val Loss: 242.3076\n",
      "Epoch [332/1000], Train Loss: 987.7339, Val Loss: 594.5551\n",
      "Epoch [333/1000], Train Loss: 148.4157, Val Loss: 164.9322\n",
      "Epoch [334/1000], Train Loss: 125.5502, Val Loss: 163.6383\n",
      "Epoch [335/1000], Train Loss: 120.0400, Val Loss: 186.3185\n",
      "Epoch [336/1000], Train Loss: 141.0272, Val Loss: 238.8357\n",
      "Epoch [337/1000], Train Loss: 168.8869, Val Loss: 214.5006\n",
      "Epoch [338/1000], Train Loss: 140.7079, Val Loss: 279.5695\n",
      "Epoch [339/1000], Train Loss: 384.3470, Val Loss: 155.5291\n",
      "Epoch [340/1000], Train Loss: 352.1912, Val Loss: 183.7108\n",
      "Epoch [341/1000], Train Loss: 133.2483, Val Loss: 417.3113\n",
      "Epoch [342/1000], Train Loss: 272.4211, Val Loss: 160.9796\n",
      "Epoch [343/1000], Train Loss: 152.3867, Val Loss: 304.0971\n",
      "Epoch [344/1000], Train Loss: 158.9015, Val Loss: 126.9731\n",
      "Epoch [345/1000], Train Loss: 2568.7524, Val Loss: 40406.8991\n",
      "Epoch [346/1000], Train Loss: 4517.7502, Val Loss: 210.7749\n",
      "Epoch [347/1000], Train Loss: 144.1342, Val Loss: 173.9523\n",
      "Epoch [348/1000], Train Loss: 131.5071, Val Loss: 146.6087\n",
      "Epoch [349/1000], Train Loss: 115.4456, Val Loss: 130.4193\n",
      "Epoch [350/1000], Train Loss: 109.4910, Val Loss: 165.8024\n",
      "Epoch [351/1000], Train Loss: 110.0888, Val Loss: 145.1124\n",
      "Epoch [352/1000], Train Loss: 114.2579, Val Loss: 128.3243\n",
      "Epoch [353/1000], Train Loss: 107.1626, Val Loss: 121.8406\n",
      "Epoch [354/1000], Train Loss: 105.6947, Val Loss: 134.6595\n",
      "Epoch [355/1000], Train Loss: 104.1325, Val Loss: 161.5472\n",
      "Epoch [356/1000], Train Loss: 103.4687, Val Loss: 117.9106\n",
      "Epoch [357/1000], Train Loss: 105.4020, Val Loss: 141.4090\n",
      "Epoch [358/1000], Train Loss: 109.7209, Val Loss: 126.0730\n",
      "Epoch [359/1000], Train Loss: 103.0929, Val Loss: 119.6419\n",
      "Epoch [360/1000], Train Loss: 103.1689, Val Loss: 118.9642\n",
      "Epoch [361/1000], Train Loss: 106.8280, Val Loss: 126.2546\n",
      "Epoch [362/1000], Train Loss: 126.8436, Val Loss: 231.8503\n",
      "Epoch [363/1000], Train Loss: 164.0355, Val Loss: 152.6736\n",
      "Epoch [364/1000], Train Loss: 124.0776, Val Loss: 116.7606\n",
      "Epoch [365/1000], Train Loss: 100.5921, Val Loss: 201.6937\n",
      "Epoch [366/1000], Train Loss: 111.7783, Val Loss: 141.3032\n",
      "Epoch [367/1000], Train Loss: 179.5129, Val Loss: 169.0546\n",
      "Epoch [368/1000], Train Loss: 164.3931, Val Loss: 120.9441\n",
      "Epoch [369/1000], Train Loss: 117.2518, Val Loss: 128.1113\n",
      "Epoch [370/1000], Train Loss: 127.0678, Val Loss: 175.3083\n",
      "Epoch [371/1000], Train Loss: 244.9268, Val Loss: 146.8697\n",
      "Epoch [372/1000], Train Loss: 257.0741, Val Loss: 337.6845\n",
      "Epoch [373/1000], Train Loss: 202.0787, Val Loss: 150.5447\n",
      "Epoch [374/1000], Train Loss: 158.5898, Val Loss: 115.4673\n",
      "Epoch [375/1000], Train Loss: 254.1739, Val Loss: 252.1307\n",
      "Epoch [376/1000], Train Loss: 350.9715, Val Loss: 925.9131\n",
      "Epoch [377/1000], Train Loss: 245.7201, Val Loss: 259.8031\n",
      "Epoch [378/1000], Train Loss: 194.2401, Val Loss: 135.3939\n",
      "Epoch [379/1000], Train Loss: 135.9483, Val Loss: 370.4342\n",
      "Epoch [380/1000], Train Loss: 124.1095, Val Loss: 129.3246\n",
      "Epoch [381/1000], Train Loss: 253.7893, Val Loss: 227.6961\n",
      "Epoch [382/1000], Train Loss: 198.0528, Val Loss: 116.6629\n",
      "Epoch [383/1000], Train Loss: 215.0360, Val Loss: 289.4771\n",
      "Epoch [384/1000], Train Loss: 764.1292, Val Loss: 852.7144\n",
      "Epoch [385/1000], Train Loss: 2608.0331, Val Loss: 722.4774\n",
      "Epoch [386/1000], Train Loss: 256.4856, Val Loss: 115.1484\n",
      "Epoch [387/1000], Train Loss: 99.0964, Val Loss: 115.8244\n",
      "Epoch [388/1000], Train Loss: 96.1883, Val Loss: 112.0164\n",
      "Epoch [389/1000], Train Loss: 92.2923, Val Loss: 108.3296\n",
      "Epoch [390/1000], Train Loss: 87.8965, Val Loss: 107.8842\n",
      "Epoch [391/1000], Train Loss: 89.0110, Val Loss: 108.4601\n",
      "Epoch [392/1000], Train Loss: 93.3593, Val Loss: 101.6030\n",
      "Epoch [393/1000], Train Loss: 87.2381, Val Loss: 103.3876\n",
      "Epoch [394/1000], Train Loss: 100.1397, Val Loss: 110.1871\n",
      "Epoch [395/1000], Train Loss: 91.2882, Val Loss: 113.8732\n",
      "Epoch [396/1000], Train Loss: 117.4522, Val Loss: 191.5692\n",
      "Epoch [397/1000], Train Loss: 103.6191, Val Loss: 134.3724\n",
      "Epoch [398/1000], Train Loss: 117.3054, Val Loss: 333.7416\n",
      "Epoch [399/1000], Train Loss: 128.3909, Val Loss: 122.9889\n",
      "Epoch [400/1000], Train Loss: 118.4266, Val Loss: 125.0732\n",
      "Epoch [401/1000], Train Loss: 170.0226, Val Loss: 299.1051\n",
      "Epoch [402/1000], Train Loss: 169.9473, Val Loss: 100.8584\n",
      "Epoch [403/1000], Train Loss: 129.1699, Val Loss: 126.7038\n",
      "Epoch [404/1000], Train Loss: 178.8320, Val Loss: 129.3442\n",
      "Epoch [405/1000], Train Loss: 1475.8770, Val Loss: 138.9798\n",
      "Epoch [406/1000], Train Loss: 99.3745, Val Loss: 140.0030\n",
      "Epoch [407/1000], Train Loss: 84.2572, Val Loss: 152.1803\n",
      "Epoch [408/1000], Train Loss: 100.5245, Val Loss: 103.1041\n",
      "Epoch [409/1000], Train Loss: 85.2651, Val Loss: 111.3230\n",
      "Epoch [410/1000], Train Loss: 93.1498, Val Loss: 104.1746\n",
      "Epoch [411/1000], Train Loss: 97.2588, Val Loss: 103.1927\n",
      "Epoch [412/1000], Train Loss: 200.0602, Val Loss: 126.2383\n",
      "Epoch [413/1000], Train Loss: 103.8367, Val Loss: 219.4642\n",
      "Epoch [414/1000], Train Loss: 110.5422, Val Loss: 209.2267\n",
      "Epoch [415/1000], Train Loss: 120.3350, Val Loss: 139.4620\n",
      "Epoch [416/1000], Train Loss: 401.3641, Val Loss: 840.8865\n",
      "Epoch [417/1000], Train Loss: 280.4349, Val Loss: 104.0641\n",
      "Epoch [418/1000], Train Loss: 106.1057, Val Loss: 391.9521\n",
      "Epoch [419/1000], Train Loss: 217.5062, Val Loss: 298.2878\n",
      "Epoch [420/1000], Train Loss: 223.3484, Val Loss: 109.4546\n",
      "Epoch [421/1000], Train Loss: 243.4131, Val Loss: 115.0696\n",
      "Epoch [422/1000], Train Loss: 132.1635, Val Loss: 101.3084\n",
      "Epoch [423/1000], Train Loss: 130.1569, Val Loss: 109.3306\n",
      "Epoch [424/1000], Train Loss: 104.7687, Val Loss: 111.5814\n",
      "Epoch [425/1000], Train Loss: 742.2130, Val Loss: 265.1442\n",
      "Epoch [426/1000], Train Loss: 115.5456, Val Loss: 100.9450\n",
      "Epoch [427/1000], Train Loss: 86.7474, Val Loss: 108.8633\n",
      "Epoch [428/1000], Train Loss: 212.1925, Val Loss: 177.3187\n",
      "Epoch [429/1000], Train Loss: 237.7737, Val Loss: 184.5675\n",
      "Epoch [430/1000], Train Loss: 149.1705, Val Loss: 95.8668\n",
      "Epoch [431/1000], Train Loss: 100.1170, Val Loss: 98.0188\n",
      "Epoch [432/1000], Train Loss: 88.6561, Val Loss: 130.2201\n",
      "Epoch [433/1000], Train Loss: 103.8445, Val Loss: 185.2920\n",
      "Epoch [434/1000], Train Loss: 583.8734, Val Loss: 169.8511\n",
      "Epoch [435/1000], Train Loss: 190.3631, Val Loss: 95.3917\n",
      "Epoch [436/1000], Train Loss: 3083.6965, Val Loss: 1340.3827\n",
      "Epoch [437/1000], Train Loss: 212.1658, Val Loss: 109.1062\n",
      "Epoch [438/1000], Train Loss: 80.0286, Val Loss: 91.7529\n",
      "Epoch [439/1000], Train Loss: 76.4292, Val Loss: 96.6259\n",
      "Epoch [440/1000], Train Loss: 83.3412, Val Loss: 100.4858\n",
      "Epoch [441/1000], Train Loss: 74.3244, Val Loss: 89.5726\n",
      "Epoch [442/1000], Train Loss: 75.3373, Val Loss: 88.9482\n",
      "Epoch [443/1000], Train Loss: 74.9071, Val Loss: 112.5876\n",
      "Epoch [444/1000], Train Loss: 80.3007, Val Loss: 109.8006\n",
      "Epoch [445/1000], Train Loss: 79.7757, Val Loss: 169.4156\n",
      "Epoch [446/1000], Train Loss: 83.9814, Val Loss: 90.2938\n",
      "Epoch [447/1000], Train Loss: 77.2706, Val Loss: 101.1571\n",
      "Epoch [448/1000], Train Loss: 89.0028, Val Loss: 207.9729\n",
      "Epoch [449/1000], Train Loss: 86.5853, Val Loss: 96.7649\n",
      "Epoch [450/1000], Train Loss: 73.9576, Val Loss: 86.1325\n",
      "Epoch [451/1000], Train Loss: 80.9945, Val Loss: 97.8470\n",
      "Epoch [452/1000], Train Loss: 86.4269, Val Loss: 95.7893\n",
      "Epoch [453/1000], Train Loss: 97.5102, Val Loss: 484.8800\n",
      "Epoch [454/1000], Train Loss: 163.0640, Val Loss: 94.0955\n",
      "Epoch [455/1000], Train Loss: 170.6052, Val Loss: 128.6375\n",
      "Epoch [456/1000], Train Loss: 1240.6535, Val Loss: 108.6413\n",
      "Epoch [457/1000], Train Loss: 99.0745, Val Loss: 123.6245\n",
      "Epoch [458/1000], Train Loss: 78.3072, Val Loss: 102.9435\n",
      "Epoch [459/1000], Train Loss: 75.8723, Val Loss: 86.7241\n",
      "Epoch [460/1000], Train Loss: 71.8404, Val Loss: 155.2152\n",
      "Epoch [461/1000], Train Loss: 116.1489, Val Loss: 82.8356\n",
      "Epoch [462/1000], Train Loss: 922.6940, Val Loss: 6278.7671\n",
      "Epoch [463/1000], Train Loss: 3648.2838, Val Loss: 207.6801\n",
      "Epoch [464/1000], Train Loss: 88.9584, Val Loss: 89.8529\n",
      "Epoch [465/1000], Train Loss: 74.3300, Val Loss: 86.1577\n",
      "Epoch [466/1000], Train Loss: 68.1635, Val Loss: 87.1459\n",
      "Epoch [467/1000], Train Loss: 71.8239, Val Loss: 97.8633\n",
      "Epoch [468/1000], Train Loss: 69.6984, Val Loss: 84.3593\n",
      "Epoch [469/1000], Train Loss: 72.8977, Val Loss: 82.0358\n",
      "Epoch [470/1000], Train Loss: 67.7812, Val Loss: 91.8981\n",
      "Epoch [471/1000], Train Loss: 67.3458, Val Loss: 83.8414\n",
      "Epoch [472/1000], Train Loss: 67.7669, Val Loss: 90.7788\n",
      "Epoch [473/1000], Train Loss: 72.3797, Val Loss: 80.8569\n",
      "Epoch [474/1000], Train Loss: 76.1517, Val Loss: 88.7696\n",
      "Epoch [475/1000], Train Loss: 70.5726, Val Loss: 101.3230\n",
      "Epoch [476/1000], Train Loss: 70.3045, Val Loss: 79.1257\n",
      "Epoch [477/1000], Train Loss: 88.7462, Val Loss: 137.6407\n",
      "Epoch [478/1000], Train Loss: 94.9913, Val Loss: 80.7025\n",
      "Epoch [479/1000], Train Loss: 69.5497, Val Loss: 181.3773\n",
      "Epoch [480/1000], Train Loss: 168.0086, Val Loss: 200.0744\n",
      "Epoch [481/1000], Train Loss: 86.0139, Val Loss: 100.7287\n",
      "Epoch [482/1000], Train Loss: 81.1298, Val Loss: 103.0278\n",
      "Epoch [483/1000], Train Loss: 153.6593, Val Loss: 80.0394\n",
      "Epoch [484/1000], Train Loss: 88.9897, Val Loss: 96.8313\n",
      "Epoch [485/1000], Train Loss: 2871.0838, Val Loss: 4273.4777\n",
      "Epoch [486/1000], Train Loss: 505.4338, Val Loss: 86.9195\n",
      "Epoch [487/1000], Train Loss: 71.5761, Val Loss: 83.7159\n",
      "Epoch [488/1000], Train Loss: 64.4335, Val Loss: 78.3779\n",
      "Epoch [489/1000], Train Loss: 70.3219, Val Loss: 78.2090\n",
      "Epoch [490/1000], Train Loss: 62.1360, Val Loss: 94.2234\n",
      "Epoch [491/1000], Train Loss: 67.0045, Val Loss: 91.7148\n",
      "Epoch [492/1000], Train Loss: 69.6554, Val Loss: 75.4794\n",
      "Epoch [493/1000], Train Loss: 73.4288, Val Loss: 76.5649\n",
      "Epoch [494/1000], Train Loss: 83.5860, Val Loss: 76.6720\n",
      "Epoch [495/1000], Train Loss: 69.0853, Val Loss: 79.9163\n",
      "Epoch [496/1000], Train Loss: 65.1274, Val Loss: 108.2729\n",
      "Epoch [497/1000], Train Loss: 65.9446, Val Loss: 79.8753\n",
      "Epoch [498/1000], Train Loss: 68.7078, Val Loss: 80.5648\n",
      "Epoch [499/1000], Train Loss: 97.2385, Val Loss: 99.2250\n",
      "Epoch [500/1000], Train Loss: 100.0968, Val Loss: 97.8248\n",
      "Epoch [501/1000], Train Loss: 103.2909, Val Loss: 342.7988\n",
      "Epoch [502/1000], Train Loss: 100.1006, Val Loss: 100.9725\n",
      "Epoch [503/1000], Train Loss: 82.2246, Val Loss: 101.0172\n",
      "Epoch [504/1000], Train Loss: 484.4895, Val Loss: 645.8647\n",
      "Epoch [505/1000], Train Loss: 230.0035, Val Loss: 97.2154\n",
      "Epoch [506/1000], Train Loss: 69.0180, Val Loss: 74.8578\n",
      "Epoch [507/1000], Train Loss: 120.3498, Val Loss: 350.2401\n",
      "Epoch [508/1000], Train Loss: 399.3622, Val Loss: 85.3621\n",
      "Epoch [509/1000], Train Loss: 156.9702, Val Loss: 242.8270\n",
      "Epoch [510/1000], Train Loss: 89.1087, Val Loss: 79.4826\n",
      "Epoch [511/1000], Train Loss: 63.6984, Val Loss: 80.0968\n",
      "Epoch [512/1000], Train Loss: 194.1539, Val Loss: 133.5650\n",
      "Epoch [513/1000], Train Loss: 213.0015, Val Loss: 95.1838\n",
      "Epoch [514/1000], Train Loss: 79.3096, Val Loss: 76.1160\n",
      "Epoch [515/1000], Train Loss: 134.2975, Val Loss: 101.9188\n",
      "Epoch [516/1000], Train Loss: 171.3780, Val Loss: 242.1263\n",
      "Epoch [517/1000], Train Loss: 150.7046, Val Loss: 109.7188\n",
      "Epoch [518/1000], Train Loss: 1450.4177, Val Loss: 1125.6086\n",
      "Epoch [519/1000], Train Loss: 282.5782, Val Loss: 108.2473\n",
      "Epoch [520/1000], Train Loss: 75.7656, Val Loss: 92.9778\n",
      "Epoch [521/1000], Train Loss: 62.9886, Val Loss: 73.9828\n",
      "Epoch [522/1000], Train Loss: 73.3649, Val Loss: 100.4830\n",
      "Epoch [523/1000], Train Loss: 68.4448, Val Loss: 81.4148\n",
      "Epoch [524/1000], Train Loss: 94.4960, Val Loss: 561.7739\n",
      "Epoch [525/1000], Train Loss: 76.7354, Val Loss: 73.7218\n",
      "Epoch [526/1000], Train Loss: 75.6477, Val Loss: 77.5438\n",
      "Epoch [527/1000], Train Loss: 75.3710, Val Loss: 84.8321\n",
      "Epoch [528/1000], Train Loss: 94.3095, Val Loss: 555.2486\n",
      "Epoch [529/1000], Train Loss: 601.3062, Val Loss: 80.9276\n",
      "Epoch [530/1000], Train Loss: 86.8917, Val Loss: 156.3210\n",
      "Epoch [531/1000], Train Loss: 206.7591, Val Loss: 80.2310\n",
      "Epoch [532/1000], Train Loss: 70.8972, Val Loss: 77.9133\n",
      "Epoch [533/1000], Train Loss: 71.7975, Val Loss: 72.7187\n",
      "Epoch [534/1000], Train Loss: 312.5385, Val Loss: 135.0147\n",
      "Epoch [535/1000], Train Loss: 72.3974, Val Loss: 99.3864\n",
      "Epoch [536/1000], Train Loss: 191.0161, Val Loss: 156.9836\n",
      "Epoch [537/1000], Train Loss: 473.0688, Val Loss: 110.1277\n",
      "Epoch [538/1000], Train Loss: 67.6749, Val Loss: 79.2520\n",
      "Epoch [539/1000], Train Loss: 124.0536, Val Loss: 71.3244\n",
      "Epoch [540/1000], Train Loss: 103.6185, Val Loss: 237.0423\n",
      "Epoch [541/1000], Train Loss: 88.8158, Val Loss: 70.6661\n",
      "Epoch [542/1000], Train Loss: 142.9414, Val Loss: 506.9294\n",
      "Epoch [543/1000], Train Loss: 1726.4009, Val Loss: 190.3156\n",
      "Epoch [544/1000], Train Loss: 216.5975, Val Loss: 82.5606\n",
      "Epoch [545/1000], Train Loss: 65.9407, Val Loss: 69.8075\n",
      "Epoch [546/1000], Train Loss: 61.4697, Val Loss: 93.0618\n",
      "Epoch [547/1000], Train Loss: 89.9176, Val Loss: 85.8784\n",
      "Epoch [548/1000], Train Loss: 58.5133, Val Loss: 69.6266\n",
      "Epoch [549/1000], Train Loss: 70.3874, Val Loss: 67.3072\n",
      "Epoch [550/1000], Train Loss: 67.3843, Val Loss: 71.9959\n",
      "Epoch [551/1000], Train Loss: 70.0507, Val Loss: 84.3276\n",
      "Epoch [552/1000], Train Loss: 110.8037, Val Loss: 88.7809\n",
      "Epoch [553/1000], Train Loss: 92.6821, Val Loss: 136.8876\n",
      "Epoch [554/1000], Train Loss: 285.9136, Val Loss: 149.3112\n",
      "Epoch [555/1000], Train Loss: 81.9840, Val Loss: 191.3008\n",
      "Epoch [556/1000], Train Loss: 160.9414, Val Loss: 96.7963\n",
      "Epoch [557/1000], Train Loss: 66.5910, Val Loss: 78.5480\n",
      "Epoch [558/1000], Train Loss: 67.3768, Val Loss: 73.2517\n",
      "Epoch [559/1000], Train Loss: 59.3461, Val Loss: 68.7284\n",
      "Epoch [560/1000], Train Loss: 385.9792, Val Loss: 108.3441\n",
      "Epoch [561/1000], Train Loss: 106.4111, Val Loss: 74.3558\n",
      "Epoch [562/1000], Train Loss: 71.9101, Val Loss: 86.1027\n",
      "Epoch [563/1000], Train Loss: 191.4668, Val Loss: 68.3599\n",
      "Epoch [564/1000], Train Loss: 147.7776, Val Loss: 642.0286\n",
      "Epoch [565/1000], Train Loss: 128.1739, Val Loss: 131.2492\n",
      "Epoch [566/1000], Train Loss: 119.3478, Val Loss: 367.9448\n",
      "Epoch [567/1000], Train Loss: 145.9812, Val Loss: 197.0432\n",
      "Epoch [568/1000], Train Loss: 124.7208, Val Loss: 660.3950\n",
      "Epoch [569/1000], Train Loss: 269.8772, Val Loss: 80.0003\n",
      "Epoch [570/1000], Train Loss: 261.0547, Val Loss: 144.0213\n",
      "Epoch [571/1000], Train Loss: 123.7264, Val Loss: 71.5561\n",
      "Epoch [572/1000], Train Loss: 975.5329, Val Loss: 399.9729\n",
      "Epoch [573/1000], Train Loss: 92.7612, Val Loss: 98.7541\n",
      "Epoch [574/1000], Train Loss: 66.1225, Val Loss: 71.3369\n",
      "Epoch [575/1000], Train Loss: 55.0405, Val Loss: 77.4831\n",
      "Epoch [576/1000], Train Loss: 72.2896, Val Loss: 70.8618\n",
      "Epoch [577/1000], Train Loss: 79.2402, Val Loss: 84.8384\n",
      "Epoch [578/1000], Train Loss: 55.3780, Val Loss: 159.7280\n",
      "Epoch [579/1000], Train Loss: 133.6460, Val Loss: 123.4117\n",
      "Epoch [580/1000], Train Loss: 189.7770, Val Loss: 668.4701\n",
      "Epoch [581/1000], Train Loss: 118.9250, Val Loss: 156.8426\n",
      "Epoch [582/1000], Train Loss: 175.2692, Val Loss: 74.5015\n",
      "Epoch [583/1000], Train Loss: 115.7802, Val Loss: 111.3106\n",
      "Epoch [584/1000], Train Loss: 85.2471, Val Loss: 98.3518\n",
      "Epoch [585/1000], Train Loss: 941.1944, Val Loss: 108.5006\n",
      "Epoch [586/1000], Train Loss: 61.0507, Val Loss: 140.1320\n",
      "Epoch [587/1000], Train Loss: 60.2427, Val Loss: 81.5153\n",
      "Epoch [588/1000], Train Loss: 64.7208, Val Loss: 111.7531\n",
      "Epoch [589/1000], Train Loss: 77.5126, Val Loss: 95.9410\n",
      "Epoch [590/1000], Train Loss: 56.5023, Val Loss: 273.9478\n",
      "Epoch [591/1000], Train Loss: 165.3779, Val Loss: 72.4648\n",
      "Epoch [592/1000], Train Loss: 262.7365, Val Loss: 1564.5105\n",
      "Epoch [593/1000], Train Loss: 459.4292, Val Loss: 120.9395\n",
      "Epoch [594/1000], Train Loss: 57.9083, Val Loss: 63.2873\n",
      "Epoch [595/1000], Train Loss: 57.8075, Val Loss: 81.3647\n",
      "Epoch [596/1000], Train Loss: 53.0507, Val Loss: 75.0643\n",
      "Epoch [597/1000], Train Loss: 502.0711, Val Loss: 7614.0191\n",
      "Epoch [598/1000], Train Loss: 4278.0243, Val Loss: 154.5082\n",
      "Epoch [599/1000], Train Loss: 67.3731, Val Loss: 69.8879\n",
      "Epoch [600/1000], Train Loss: 52.6225, Val Loss: 72.2425\n",
      "Epoch [601/1000], Train Loss: 50.8959, Val Loss: 68.0609\n",
      "Epoch [602/1000], Train Loss: 49.0003, Val Loss: 60.9864\n",
      "Epoch [603/1000], Train Loss: 46.7674, Val Loss: 67.3910\n",
      "Epoch [604/1000], Train Loss: 52.7375, Val Loss: 61.9807\n",
      "Epoch [605/1000], Train Loss: 47.6691, Val Loss: 59.8521\n",
      "Epoch [606/1000], Train Loss: 47.4878, Val Loss: 71.7360\n",
      "Epoch [607/1000], Train Loss: 46.8525, Val Loss: 63.1527\n",
      "Epoch [608/1000], Train Loss: 48.6170, Val Loss: 63.1456\n",
      "Epoch [609/1000], Train Loss: 51.0093, Val Loss: 73.7829\n",
      "Epoch [610/1000], Train Loss: 48.9654, Val Loss: 59.5973\n",
      "Epoch [611/1000], Train Loss: 46.2654, Val Loss: 62.1398\n",
      "Epoch [612/1000], Train Loss: 52.2476, Val Loss: 69.3770\n",
      "Epoch [613/1000], Train Loss: 51.2190, Val Loss: 205.6467\n",
      "Epoch [614/1000], Train Loss: 75.8918, Val Loss: 60.0103\n",
      "Epoch [615/1000], Train Loss: 80.0054, Val Loss: 129.7007\n",
      "Epoch [616/1000], Train Loss: 52.7088, Val Loss: 62.4803\n",
      "Epoch [617/1000], Train Loss: 66.0811, Val Loss: 65.8204\n",
      "Epoch [618/1000], Train Loss: 53.6724, Val Loss: 73.9711\n",
      "Epoch [619/1000], Train Loss: 78.7432, Val Loss: 63.9444\n",
      "Epoch [620/1000], Train Loss: 60.3843, Val Loss: 83.9389\n",
      "Epoch [621/1000], Train Loss: 144.7265, Val Loss: 73.6028\n",
      "Epoch [622/1000], Train Loss: 1598.1855, Val Loss: 6336.2046\n",
      "Epoch [623/1000], Train Loss: 967.4384, Val Loss: 70.1433\n",
      "Epoch [624/1000], Train Loss: 54.9856, Val Loss: 61.9637\n",
      "Epoch [625/1000], Train Loss: 51.8446, Val Loss: 58.7990\n",
      "Epoch [626/1000], Train Loss: 50.4030, Val Loss: 59.7668\n",
      "Epoch [627/1000], Train Loss: 46.6263, Val Loss: 66.2046\n",
      "Epoch [628/1000], Train Loss: 48.2773, Val Loss: 56.8013\n",
      "Epoch [629/1000], Train Loss: 46.4004, Val Loss: 56.2578\n",
      "Epoch [630/1000], Train Loss: 44.1305, Val Loss: 61.0294\n",
      "Epoch [631/1000], Train Loss: 57.9220, Val Loss: 61.8158\n",
      "Epoch [632/1000], Train Loss: 49.5013, Val Loss: 104.7713\n",
      "Epoch [633/1000], Train Loss: 53.3176, Val Loss: 78.2785\n",
      "Epoch [634/1000], Train Loss: 206.3664, Val Loss: 294.8188\n",
      "Epoch [635/1000], Train Loss: 107.2112, Val Loss: 91.8669\n",
      "Epoch [636/1000], Train Loss: 59.4164, Val Loss: 78.1089\n",
      "Epoch [637/1000], Train Loss: 91.0174, Val Loss: 85.7604\n",
      "Epoch [638/1000], Train Loss: 76.2059, Val Loss: 78.5004\n",
      "Epoch [639/1000], Train Loss: 103.0089, Val Loss: 138.5285\n",
      "Epoch [640/1000], Train Loss: 344.4419, Val Loss: 62.9194\n",
      "Epoch [641/1000], Train Loss: 54.0290, Val Loss: 64.3605\n",
      "Epoch [642/1000], Train Loss: 186.4129, Val Loss: 139.4933\n",
      "Epoch [643/1000], Train Loss: 315.8512, Val Loss: 148.6307\n",
      "Epoch [644/1000], Train Loss: 86.4206, Val Loss: 101.7888\n",
      "Epoch [645/1000], Train Loss: 121.7191, Val Loss: 77.4368\n",
      "Epoch [646/1000], Train Loss: 240.2433, Val Loss: 172.7843\n",
      "Epoch [647/1000], Train Loss: 140.0392, Val Loss: 286.6896\n",
      "Epoch [648/1000], Train Loss: 72.5859, Val Loss: 101.7264\n",
      "Epoch [649/1000], Train Loss: 141.2389, Val Loss: 137.8784\n",
      "Epoch [650/1000], Train Loss: 84.6166, Val Loss: 57.3732\n",
      "Epoch [651/1000], Train Loss: 94.9888, Val Loss: 60.8809\n",
      "Epoch [652/1000], Train Loss: 5685.9941, Val Loss: 583.0882\n",
      "Epoch [653/1000], Train Loss: 267.1441, Val Loss: 76.5622\n",
      "Epoch [654/1000], Train Loss: 55.6821, Val Loss: 65.4837\n",
      "Epoch [655/1000], Train Loss: 48.0036, Val Loss: 63.9594\n",
      "Epoch [656/1000], Train Loss: 50.0756, Val Loss: 57.7544\n",
      "Epoch [657/1000], Train Loss: 43.8216, Val Loss: 60.5483\n",
      "Epoch [658/1000], Train Loss: 42.3896, Val Loss: 58.0614\n",
      "Epoch [659/1000], Train Loss: 40.4613, Val Loss: 58.1645\n",
      "Epoch [660/1000], Train Loss: 41.5410, Val Loss: 54.7784\n",
      "Epoch [661/1000], Train Loss: 41.0561, Val Loss: 54.3026\n",
      "Epoch [662/1000], Train Loss: 42.2639, Val Loss: 92.1440\n",
      "Epoch [663/1000], Train Loss: 46.3887, Val Loss: 54.0895\n",
      "Epoch [664/1000], Train Loss: 39.3678, Val Loss: 61.4572\n",
      "Epoch [665/1000], Train Loss: 41.9375, Val Loss: 54.8165\n",
      "Epoch [666/1000], Train Loss: 45.6735, Val Loss: 53.6681\n",
      "Epoch [667/1000], Train Loss: 40.9098, Val Loss: 56.3462\n",
      "Epoch [668/1000], Train Loss: 49.5031, Val Loss: 55.2281\n",
      "Epoch [669/1000], Train Loss: 48.1184, Val Loss: 88.3017\n",
      "Epoch [670/1000], Train Loss: 49.3256, Val Loss: 84.0197\n",
      "Epoch [671/1000], Train Loss: 58.0417, Val Loss: 58.2502\n",
      "Epoch [672/1000], Train Loss: 65.3935, Val Loss: 53.7727\n",
      "Epoch [673/1000], Train Loss: 73.1492, Val Loss: 219.7077\n",
      "Epoch [674/1000], Train Loss: 160.7264, Val Loss: 237.2509\n",
      "Epoch [675/1000], Train Loss: 205.3946, Val Loss: 79.0065\n",
      "Epoch [676/1000], Train Loss: 47.9032, Val Loss: 76.4084\n",
      "Epoch [677/1000], Train Loss: 53.4804, Val Loss: 94.9164\n",
      "Epoch [678/1000], Train Loss: 74.6018, Val Loss: 155.3513\n",
      "Epoch [679/1000], Train Loss: 279.0089, Val Loss: 1183.4679\n",
      "Epoch [680/1000], Train Loss: 190.0222, Val Loss: 433.9097\n",
      "Epoch [681/1000], Train Loss: 244.5576, Val Loss: 622.0218\n",
      "Epoch [682/1000], Train Loss: 300.5029, Val Loss: 94.0938\n",
      "Epoch [683/1000], Train Loss: 52.6336, Val Loss: 55.7186\n",
      "Epoch [684/1000], Train Loss: 49.5072, Val Loss: 391.5295\n",
      "Epoch [685/1000], Train Loss: 137.5092, Val Loss: 81.7602\n",
      "Epoch [686/1000], Train Loss: 671.1014, Val Loss: 362.4782\n",
      "Epoch [687/1000], Train Loss: 129.8283, Val Loss: 53.6760\n",
      "Epoch [688/1000], Train Loss: 45.8607, Val Loss: 58.3363\n",
      "Epoch [689/1000], Train Loss: 51.2008, Val Loss: 69.9551\n",
      "Epoch [690/1000], Train Loss: 97.7608, Val Loss: 58.7188\n",
      "Epoch [691/1000], Train Loss: 69.1986, Val Loss: 56.0372\n",
      "Epoch [692/1000], Train Loss: 56.2893, Val Loss: 56.8245\n",
      "Epoch [693/1000], Train Loss: 76.9609, Val Loss: 53.4604\n",
      "Epoch [694/1000], Train Loss: 103.2330, Val Loss: 100.0662\n",
      "Epoch [695/1000], Train Loss: 2454.7173, Val Loss: 951.4602\n",
      "Epoch [696/1000], Train Loss: 162.3031, Val Loss: 58.5040\n",
      "Epoch [697/1000], Train Loss: 46.4760, Val Loss: 57.1834\n",
      "Epoch [698/1000], Train Loss: 42.8323, Val Loss: 61.4555\n",
      "Epoch [699/1000], Train Loss: 39.0345, Val Loss: 50.7864\n",
      "Epoch [700/1000], Train Loss: 37.9570, Val Loss: 52.0613\n",
      "Epoch [701/1000], Train Loss: 38.0394, Val Loss: 63.4005\n",
      "Epoch [702/1000], Train Loss: 54.0898, Val Loss: 50.5862\n",
      "Epoch [703/1000], Train Loss: 50.9766, Val Loss: 48.8065\n",
      "Epoch [704/1000], Train Loss: 47.0802, Val Loss: 160.5254\n",
      "Epoch [705/1000], Train Loss: 47.5569, Val Loss: 51.4782\n",
      "Epoch [706/1000], Train Loss: 40.1475, Val Loss: 60.9434\n",
      "Epoch [707/1000], Train Loss: 65.5312, Val Loss: 51.0648\n",
      "Epoch [708/1000], Train Loss: 70.0149, Val Loss: 93.8948\n",
      "Epoch [709/1000], Train Loss: 79.6090, Val Loss: 156.0841\n",
      "Epoch [710/1000], Train Loss: 3522.4114, Val Loss: 323.7227\n",
      "Epoch [711/1000], Train Loss: 127.9563, Val Loss: 64.7064\n",
      "Epoch [712/1000], Train Loss: 45.5311, Val Loss: 58.0108\n",
      "Epoch [713/1000], Train Loss: 40.1231, Val Loss: 52.7291\n",
      "Epoch [714/1000], Train Loss: 39.8096, Val Loss: 74.6723\n",
      "Epoch [715/1000], Train Loss: 41.0867, Val Loss: 50.8913\n",
      "Epoch [716/1000], Train Loss: 37.3531, Val Loss: 84.0448\n",
      "Epoch [717/1000], Train Loss: 41.6925, Val Loss: 51.3300\n",
      "Epoch [718/1000], Train Loss: 39.8166, Val Loss: 48.8186\n",
      "Epoch [719/1000], Train Loss: 38.6351, Val Loss: 51.2082\n",
      "Epoch [720/1000], Train Loss: 46.1702, Val Loss: 51.3815\n",
      "Epoch [721/1000], Train Loss: 36.8645, Val Loss: 49.7601\n",
      "Epoch [722/1000], Train Loss: 38.2932, Val Loss: 50.7643\n",
      "Epoch [723/1000], Train Loss: 37.3571, Val Loss: 56.4470\n",
      "Epoch [724/1000], Train Loss: 47.9685, Val Loss: 48.1998\n",
      "Epoch [725/1000], Train Loss: 39.3732, Val Loss: 58.4069\n",
      "Epoch [726/1000], Train Loss: 51.8050, Val Loss: 65.7883\n",
      "Epoch [727/1000], Train Loss: 51.2586, Val Loss: 111.7896\n",
      "Epoch [728/1000], Train Loss: 65.2441, Val Loss: 65.2501\n",
      "Epoch [729/1000], Train Loss: 306.0265, Val Loss: 102.1737\n",
      "Epoch [730/1000], Train Loss: 75.7488, Val Loss: 61.2796\n",
      "Epoch [731/1000], Train Loss: 84.6720, Val Loss: 58.6197\n",
      "Epoch [732/1000], Train Loss: 486.9784, Val Loss: 396.1754\n",
      "Epoch [733/1000], Train Loss: 111.1024, Val Loss: 54.6839\n",
      "Epoch [734/1000], Train Loss: 44.1358, Val Loss: 71.3412\n",
      "Epoch [735/1000], Train Loss: 46.9250, Val Loss: 61.6344\n",
      "Epoch [736/1000], Train Loss: 52.5703, Val Loss: 132.4292\n",
      "Epoch [737/1000], Train Loss: 124.8619, Val Loss: 224.8763\n",
      "Epoch [738/1000], Train Loss: 75.4712, Val Loss: 56.6512\n",
      "Epoch [739/1000], Train Loss: 864.9816, Val Loss: 15168.7965\n",
      "Epoch [740/1000], Train Loss: 1929.0623, Val Loss: 76.5656\n",
      "Epoch [741/1000], Train Loss: 54.7717, Val Loss: 51.9058\n",
      "Epoch [742/1000], Train Loss: 37.0458, Val Loss: 49.4369\n",
      "Epoch [743/1000], Train Loss: 40.1808, Val Loss: 48.1826\n",
      "Epoch [744/1000], Train Loss: 34.8599, Val Loss: 47.7399\n",
      "Epoch [745/1000], Train Loss: 37.8763, Val Loss: 55.4778\n",
      "Epoch [746/1000], Train Loss: 35.5827, Val Loss: 48.9702\n",
      "Epoch [747/1000], Train Loss: 39.4668, Val Loss: 51.8117\n",
      "Epoch [748/1000], Train Loss: 36.8859, Val Loss: 57.5977\n",
      "Epoch [749/1000], Train Loss: 43.9066, Val Loss: 53.6073\n",
      "Epoch [750/1000], Train Loss: 62.3436, Val Loss: 59.9420\n",
      "Epoch [751/1000], Train Loss: 73.7727, Val Loss: 56.0639\n",
      "Epoch [752/1000], Train Loss: 44.1937, Val Loss: 82.1578\n",
      "Epoch [753/1000], Train Loss: 61.9960, Val Loss: 49.4991\n",
      "Epoch [754/1000], Train Loss: 59.7124, Val Loss: 52.9292\n",
      "Epoch [755/1000], Train Loss: 54.0862, Val Loss: 46.9400\n",
      "Epoch [756/1000], Train Loss: 50.0554, Val Loss: 109.7912\n",
      "Epoch [757/1000], Train Loss: 72.3628, Val Loss: 67.4442\n",
      "Epoch [758/1000], Train Loss: 3236.0118, Val Loss: 7809.3064\n",
      "Epoch [759/1000], Train Loss: 770.6292, Val Loss: 77.7851\n",
      "Epoch [760/1000], Train Loss: 45.5416, Val Loss: 51.3538\n",
      "Epoch [761/1000], Train Loss: 40.0209, Val Loss: 51.5611\n",
      "Epoch [762/1000], Train Loss: 36.8666, Val Loss: 59.9435\n",
      "Epoch [763/1000], Train Loss: 43.5756, Val Loss: 53.4639\n",
      "Epoch [764/1000], Train Loss: 36.9777, Val Loss: 51.6771\n",
      "Epoch [765/1000], Train Loss: 37.6335, Val Loss: 52.6882\n",
      "Epoch [766/1000], Train Loss: 36.8587, Val Loss: 48.7833\n",
      "Epoch [767/1000], Train Loss: 34.4631, Val Loss: 47.8202\n",
      "Epoch [768/1000], Train Loss: 33.7315, Val Loss: 46.2048\n",
      "Epoch [769/1000], Train Loss: 40.4874, Val Loss: 45.7236\n",
      "Epoch [770/1000], Train Loss: 34.0733, Val Loss: 52.5572\n",
      "Epoch [771/1000], Train Loss: 42.8950, Val Loss: 47.1141\n",
      "Epoch [772/1000], Train Loss: 39.7431, Val Loss: 52.9111\n",
      "Epoch [773/1000], Train Loss: 37.2758, Val Loss: 57.6011\n",
      "Epoch [774/1000], Train Loss: 54.0723, Val Loss: 118.5237\n",
      "Epoch [775/1000], Train Loss: 44.0292, Val Loss: 48.6213\n",
      "Epoch [776/1000], Train Loss: 51.2354, Val Loss: 135.3049\n",
      "Epoch [777/1000], Train Loss: 143.0303, Val Loss: 97.5228\n",
      "Epoch [778/1000], Train Loss: 139.5093, Val Loss: 48.8252\n",
      "Epoch [779/1000], Train Loss: 120.9198, Val Loss: 79.1277\n",
      "Epoch [780/1000], Train Loss: 74.0174, Val Loss: 47.1590\n",
      "Epoch [781/1000], Train Loss: 127.5153, Val Loss: 637.4771\n",
      "Epoch [782/1000], Train Loss: 419.1228, Val Loss: 69.6011\n",
      "Epoch [783/1000], Train Loss: 44.9240, Val Loss: 60.0299\n",
      "Epoch [784/1000], Train Loss: 37.6732, Val Loss: 92.3890\n",
      "Epoch [785/1000], Train Loss: 80.7631, Val Loss: 90.7370\n",
      "Epoch [786/1000], Train Loss: 988.3331, Val Loss: 2021.3036\n",
      "Epoch [787/1000], Train Loss: 2622.7175, Val Loss: 363.0809\n",
      "Epoch [788/1000], Train Loss: 76.7404, Val Loss: 50.3732\n",
      "Epoch [789/1000], Train Loss: 37.9401, Val Loss: 58.3712\n",
      "Epoch [790/1000], Train Loss: 37.4022, Val Loss: 45.2398\n",
      "Epoch [791/1000], Train Loss: 33.2570, Val Loss: 54.6210\n",
      "Epoch [792/1000], Train Loss: 34.9370, Val Loss: 47.5178\n",
      "Epoch [793/1000], Train Loss: 31.8436, Val Loss: 42.8683\n",
      "Epoch [794/1000], Train Loss: 33.1192, Val Loss: 49.8588\n",
      "Epoch [795/1000], Train Loss: 33.7864, Val Loss: 59.3152\n",
      "Epoch [796/1000], Train Loss: 35.6714, Val Loss: 44.3543\n",
      "Epoch [797/1000], Train Loss: 33.0953, Val Loss: 44.4167\n",
      "Epoch [798/1000], Train Loss: 37.8137, Val Loss: 45.3470\n",
      "Epoch [799/1000], Train Loss: 36.7544, Val Loss: 66.4942\n",
      "Epoch [800/1000], Train Loss: 48.7054, Val Loss: 59.0871\n",
      "Epoch [801/1000], Train Loss: 64.4521, Val Loss: 174.0354\n",
      "Epoch [802/1000], Train Loss: 957.6135, Val Loss: 2724.5183\n",
      "Epoch [803/1000], Train Loss: 692.1469, Val Loss: 47.1883\n",
      "Epoch [804/1000], Train Loss: 36.3267, Val Loss: 47.6580\n",
      "Epoch [805/1000], Train Loss: 32.8231, Val Loss: 43.8811\n",
      "Epoch [806/1000], Train Loss: 34.6314, Val Loss: 45.6266\n",
      "Epoch [807/1000], Train Loss: 34.2362, Val Loss: 42.5107\n",
      "Epoch [808/1000], Train Loss: 37.2288, Val Loss: 42.0328\n",
      "Epoch [809/1000], Train Loss: 32.6297, Val Loss: 44.1881\n",
      "Epoch [810/1000], Train Loss: 35.1818, Val Loss: 77.8806\n",
      "Epoch [811/1000], Train Loss: 36.0253, Val Loss: 99.4605\n",
      "Epoch [812/1000], Train Loss: 61.4704, Val Loss: 64.3592\n",
      "Epoch [813/1000], Train Loss: 36.6052, Val Loss: 47.1910\n",
      "Epoch [814/1000], Train Loss: 105.1432, Val Loss: 752.5231\n",
      "Epoch [815/1000], Train Loss: 276.1897, Val Loss: 247.8566\n",
      "Epoch [816/1000], Train Loss: 55.9859, Val Loss: 42.6740\n",
      "Epoch [817/1000], Train Loss: 36.9303, Val Loss: 70.6008\n",
      "Epoch [818/1000], Train Loss: 109.6447, Val Loss: 42.3989\n",
      "Epoch [819/1000], Train Loss: 141.9860, Val Loss: 235.2165\n",
      "Epoch [820/1000], Train Loss: 452.7136, Val Loss: 502.6056\n",
      "Epoch [821/1000], Train Loss: 158.7870, Val Loss: 89.3217\n",
      "Epoch [822/1000], Train Loss: 73.8341, Val Loss: 69.4717\n",
      "Epoch [823/1000], Train Loss: 63.2276, Val Loss: 58.2263\n",
      "Epoch [824/1000], Train Loss: 67.5984, Val Loss: 43.0276\n",
      "Epoch [825/1000], Train Loss: 50.1300, Val Loss: 48.8087\n",
      "Epoch [826/1000], Train Loss: 76.3137, Val Loss: 59.2988\n",
      "Epoch [827/1000], Train Loss: 165.7113, Val Loss: 68.9324\n",
      "Epoch [828/1000], Train Loss: 139.3358, Val Loss: 205.7779\n",
      "Epoch [829/1000], Train Loss: 68.0540, Val Loss: 43.6172\n",
      "Epoch [830/1000], Train Loss: 1007.5360, Val Loss: 1789.7402\n",
      "Epoch [831/1000], Train Loss: 312.0376, Val Loss: 57.7336\n",
      "Epoch [832/1000], Train Loss: 47.2989, Val Loss: 52.6865\n",
      "Epoch [833/1000], Train Loss: 31.9167, Val Loss: 42.6464\n",
      "Epoch [834/1000], Train Loss: 31.3135, Val Loss: 49.2655\n",
      "Epoch [835/1000], Train Loss: 64.3922, Val Loss: 47.3287\n",
      "Epoch [836/1000], Train Loss: 39.2240, Val Loss: 50.2160\n",
      "Epoch [837/1000], Train Loss: 60.2637, Val Loss: 85.3542\n",
      "Epoch [838/1000], Train Loss: 163.8817, Val Loss: 50.6741\n",
      "Epoch [839/1000], Train Loss: 47.4955, Val Loss: 41.8547\n",
      "Epoch [840/1000], Train Loss: 41.9009, Val Loss: 63.9309\n",
      "Epoch [841/1000], Train Loss: 70.9758, Val Loss: 59.2052\n",
      "Epoch [842/1000], Train Loss: 103.6830, Val Loss: 160.0991\n",
      "Epoch [843/1000], Train Loss: 1196.5428, Val Loss: 113.5310\n",
      "Epoch [844/1000], Train Loss: 43.1049, Val Loss: 42.2730\n",
      "Epoch [845/1000], Train Loss: 34.2267, Val Loss: 41.1711\n",
      "Epoch [846/1000], Train Loss: 31.9269, Val Loss: 41.0509\n",
      "Epoch [847/1000], Train Loss: 34.0291, Val Loss: 64.0298\n",
      "Epoch [848/1000], Train Loss: 38.5351, Val Loss: 83.9567\n",
      "Epoch [849/1000], Train Loss: 41.3872, Val Loss: 59.7570\n",
      "Epoch [850/1000], Train Loss: 42.9941, Val Loss: 40.4140\n",
      "Epoch [851/1000], Train Loss: 198.4916, Val Loss: 75.7044\n",
      "Epoch [852/1000], Train Loss: 662.2231, Val Loss: 53.3660\n",
      "Epoch [853/1000], Train Loss: 43.4452, Val Loss: 52.4902\n",
      "Epoch [854/1000], Train Loss: 43.8533, Val Loss: 43.1658\n",
      "Epoch [855/1000], Train Loss: 40.6166, Val Loss: 102.1068\n",
      "Epoch [856/1000], Train Loss: 77.1011, Val Loss: 166.6513\n",
      "Epoch [857/1000], Train Loss: 63.6118, Val Loss: 46.6928\n",
      "Epoch [858/1000], Train Loss: 56.1855, Val Loss: 160.8696\n",
      "Epoch [859/1000], Train Loss: 99.1947, Val Loss: 72.9133\n",
      "Epoch [860/1000], Train Loss: 58.7555, Val Loss: 83.2531\n",
      "Epoch [861/1000], Train Loss: 2307.7522, Val Loss: 374.1125\n",
      "Epoch [862/1000], Train Loss: 320.6522, Val Loss: 49.9655\n",
      "Epoch [863/1000], Train Loss: 34.2774, Val Loss: 41.8600\n",
      "Epoch [864/1000], Train Loss: 34.4591, Val Loss: 44.7924\n",
      "Epoch [865/1000], Train Loss: 35.3885, Val Loss: 48.8677\n",
      "Epoch [866/1000], Train Loss: 34.5314, Val Loss: 41.0644\n",
      "Epoch [867/1000], Train Loss: 29.0516, Val Loss: 43.3736\n",
      "Epoch [868/1000], Train Loss: 32.1546, Val Loss: 52.8966\n",
      "Epoch [869/1000], Train Loss: 34.5165, Val Loss: 42.9964\n",
      "Epoch [870/1000], Train Loss: 30.5646, Val Loss: 48.3985\n",
      "Epoch [871/1000], Train Loss: 32.9492, Val Loss: 53.9043\n",
      "Epoch [872/1000], Train Loss: 33.4806, Val Loss: 50.2101\n",
      "Epoch [873/1000], Train Loss: 35.1823, Val Loss: 65.8611\n",
      "Epoch [874/1000], Train Loss: 51.4510, Val Loss: 40.9859\n",
      "Epoch [875/1000], Train Loss: 47.1069, Val Loss: 45.8820\n",
      "Epoch [876/1000], Train Loss: 41.4743, Val Loss: 68.0685\n",
      "Epoch [877/1000], Train Loss: 40.0345, Val Loss: 41.4770\n",
      "Epoch [878/1000], Train Loss: 71.7349, Val Loss: 167.7753\n",
      "Epoch [879/1000], Train Loss: 610.5086, Val Loss: 94.6698\n",
      "Epoch [880/1000], Train Loss: 76.9724, Val Loss: 89.8187\n",
      "Epoch [881/1000], Train Loss: 36.0379, Val Loss: 51.0719\n",
      "Epoch [882/1000], Train Loss: 41.0728, Val Loss: 52.0309\n",
      "Epoch [883/1000], Train Loss: 52.9960, Val Loss: 98.8793\n",
      "Epoch [884/1000], Train Loss: 119.1702, Val Loss: 819.1817\n",
      "Epoch [885/1000], Train Loss: 5023.5636, Val Loss: 111.7393\n",
      "Epoch [886/1000], Train Loss: 65.8932, Val Loss: 48.4032\n",
      "Epoch [887/1000], Train Loss: 35.0679, Val Loss: 45.6755\n",
      "Epoch [888/1000], Train Loss: 33.4146, Val Loss: 71.0117\n",
      "Epoch [889/1000], Train Loss: 32.3465, Val Loss: 53.4903\n",
      "Epoch [890/1000], Train Loss: 29.9461, Val Loss: 50.8838\n",
      "Epoch [891/1000], Train Loss: 31.2673, Val Loss: 46.9421\n",
      "Epoch [892/1000], Train Loss: 31.3400, Val Loss: 38.3441\n",
      "Epoch [893/1000], Train Loss: 29.1576, Val Loss: 41.5272\n",
      "Epoch [894/1000], Train Loss: 27.8948, Val Loss: 38.5289\n",
      "Epoch [895/1000], Train Loss: 28.2863, Val Loss: 38.9643\n",
      "Epoch [896/1000], Train Loss: 27.1516, Val Loss: 39.0910\n",
      "Epoch [897/1000], Train Loss: 34.2393, Val Loss: 47.9349\n",
      "Epoch [898/1000], Train Loss: 30.7422, Val Loss: 37.9030\n",
      "Epoch [899/1000], Train Loss: 31.1606, Val Loss: 57.7856\n",
      "Epoch [900/1000], Train Loss: 38.1416, Val Loss: 39.3929\n",
      "Epoch [901/1000], Train Loss: 33.8002, Val Loss: 43.5229\n",
      "Epoch [902/1000], Train Loss: 30.0080, Val Loss: 42.7703\n",
      "Epoch [903/1000], Train Loss: 38.2330, Val Loss: 39.7406\n",
      "Epoch [904/1000], Train Loss: 37.4010, Val Loss: 44.6388\n",
      "Epoch [905/1000], Train Loss: 62.5041, Val Loss: 119.7618\n",
      "Epoch [906/1000], Train Loss: 80.2412, Val Loss: 177.7025\n",
      "Epoch [907/1000], Train Loss: 51.2536, Val Loss: 82.9025\n",
      "Epoch [908/1000], Train Loss: 86.8717, Val Loss: 591.9161\n",
      "Epoch [909/1000], Train Loss: 201.8953, Val Loss: 52.7041\n",
      "Epoch [910/1000], Train Loss: 47.6087, Val Loss: 47.7472\n",
      "Epoch [911/1000], Train Loss: 90.3203, Val Loss: 58.7694\n",
      "Epoch [912/1000], Train Loss: 41.8675, Val Loss: 39.1210\n",
      "Epoch [913/1000], Train Loss: 534.5282, Val Loss: 976.8869\n",
      "Epoch [914/1000], Train Loss: 360.8372, Val Loss: 56.1652\n",
      "Epoch [915/1000], Train Loss: 42.6649, Val Loss: 62.5434\n",
      "Epoch [916/1000], Train Loss: 38.4065, Val Loss: 39.6922\n",
      "Epoch [917/1000], Train Loss: 29.1931, Val Loss: 36.9850\n",
      "Epoch [918/1000], Train Loss: 41.2302, Val Loss: 66.1483\n",
      "Epoch [919/1000], Train Loss: 79.3586, Val Loss: 64.7135\n",
      "Epoch [920/1000], Train Loss: 179.3521, Val Loss: 824.4785\n",
      "Epoch [921/1000], Train Loss: 198.3012, Val Loss: 1302.8052\n",
      "Epoch [922/1000], Train Loss: 3019.1114, Val Loss: 88.8786\n",
      "Epoch [923/1000], Train Loss: 45.3859, Val Loss: 44.5103\n",
      "Epoch [924/1000], Train Loss: 29.7454, Val Loss: 47.1647\n",
      "Epoch [925/1000], Train Loss: 32.8187, Val Loss: 40.9787\n",
      "Epoch [926/1000], Train Loss: 29.0296, Val Loss: 70.9798\n",
      "Epoch [927/1000], Train Loss: 28.8274, Val Loss: 37.7910\n",
      "Epoch [928/1000], Train Loss: 28.9156, Val Loss: 40.4872\n",
      "Epoch [929/1000], Train Loss: 29.2545, Val Loss: 38.5855\n",
      "Epoch [930/1000], Train Loss: 32.4793, Val Loss: 38.7073\n",
      "Epoch [931/1000], Train Loss: 30.2778, Val Loss: 38.9490\n",
      "Epoch [932/1000], Train Loss: 30.1410, Val Loss: 38.4539\n",
      "Epoch [933/1000], Train Loss: 35.6111, Val Loss: 39.6829\n",
      "Epoch [934/1000], Train Loss: 29.6490, Val Loss: 40.5716\n",
      "Epoch [935/1000], Train Loss: 46.0176, Val Loss: 39.7588\n",
      "Epoch [936/1000], Train Loss: 31.7910, Val Loss: 42.3956\n",
      "Epoch [937/1000], Train Loss: 37.9830, Val Loss: 78.8870\n",
      "Epoch [938/1000], Train Loss: 73.2818, Val Loss: 134.6566\n",
      "Epoch [939/1000], Train Loss: 56.7311, Val Loss: 60.4618\n",
      "Epoch [940/1000], Train Loss: 118.7086, Val Loss: 70.5953\n",
      "Epoch [941/1000], Train Loss: 50.5290, Val Loss: 36.1561\n",
      "Epoch [942/1000], Train Loss: 42.6735, Val Loss: 129.9720\n",
      "Epoch [943/1000], Train Loss: 103.0643, Val Loss: 59.6977\n",
      "Epoch [944/1000], Train Loss: 58.8260, Val Loss: 42.8657\n",
      "Epoch [945/1000], Train Loss: 116.8442, Val Loss: 134.0893\n",
      "Epoch [946/1000], Train Loss: 158.9661, Val Loss: 75.7218\n",
      "Epoch [947/1000], Train Loss: 767.0234, Val Loss: 342.8972\n",
      "Epoch [948/1000], Train Loss: 116.3410, Val Loss: 39.5441\n",
      "Epoch [949/1000], Train Loss: 37.4342, Val Loss: 37.8649\n",
      "Epoch [950/1000], Train Loss: 32.0301, Val Loss: 36.2098\n",
      "Epoch [951/1000], Train Loss: 68.6274, Val Loss: 174.4232\n",
      "Epoch [952/1000], Train Loss: 82.2191, Val Loss: 104.0212\n",
      "Epoch [953/1000], Train Loss: 76.4946, Val Loss: 65.6765\n",
      "Epoch [954/1000], Train Loss: 41.0210, Val Loss: 80.7981\n",
      "Epoch [955/1000], Train Loss: 79.3800, Val Loss: 156.1671\n",
      "Epoch [956/1000], Train Loss: 425.2758, Val Loss: 655.7391\n",
      "Epoch [957/1000], Train Loss: 219.7949, Val Loss: 42.2099\n",
      "Epoch [958/1000], Train Loss: 34.4022, Val Loss: 45.2622\n",
      "Epoch [959/1000], Train Loss: 30.7608, Val Loss: 51.9686\n",
      "Epoch [960/1000], Train Loss: 33.5193, Val Loss: 47.4740\n",
      "Epoch [961/1000], Train Loss: 54.9138, Val Loss: 42.7427\n",
      "Epoch [962/1000], Train Loss: 200.2021, Val Loss: 51.8153\n",
      "Epoch [963/1000], Train Loss: 78.6332, Val Loss: 82.4262\n",
      "Epoch [964/1000], Train Loss: 83.2247, Val Loss: 78.0048\n",
      "Epoch [965/1000], Train Loss: 147.1490, Val Loss: 41.7720\n",
      "Epoch [966/1000], Train Loss: 137.4400, Val Loss: 70.1203\n",
      "Epoch [967/1000], Train Loss: 189.0730, Val Loss: 1241.8835\n",
      "Epoch [968/1000], Train Loss: 1099.3161, Val Loss: 101.5408\n",
      "Epoch [969/1000], Train Loss: 59.1752, Val Loss: 36.2682\n",
      "Epoch [970/1000], Train Loss: 37.6173, Val Loss: 43.4334\n",
      "Epoch [971/1000], Train Loss: 33.1138, Val Loss: 37.4529\n",
      "Epoch [972/1000], Train Loss: 25.1380, Val Loss: 39.6650\n",
      "Epoch [973/1000], Train Loss: 41.4080, Val Loss: 183.0147\n",
      "Epoch [974/1000], Train Loss: 60.2481, Val Loss: 61.5718\n",
      "Epoch [975/1000], Train Loss: 100.5775, Val Loss: 49.0748\n",
      "Epoch [976/1000], Train Loss: 75.4971, Val Loss: 62.3073\n",
      "Epoch [977/1000], Train Loss: 31.8619, Val Loss: 35.4884\n",
      "Epoch [978/1000], Train Loss: 53.4184, Val Loss: 567.3880\n",
      "Epoch [979/1000], Train Loss: 1076.1399, Val Loss: 372.2075\n",
      "Epoch [980/1000], Train Loss: 2331.8528, Val Loss: 58.5386\n",
      "Epoch [981/1000], Train Loss: 42.5258, Val Loss: 46.9194\n",
      "Epoch [982/1000], Train Loss: 28.4372, Val Loss: 39.0719\n",
      "Epoch [983/1000], Train Loss: 26.2284, Val Loss: 35.4984\n",
      "Epoch [984/1000], Train Loss: 27.7772, Val Loss: 38.9554\n",
      "Epoch [985/1000], Train Loss: 25.6844, Val Loss: 42.3119\n",
      "Epoch [986/1000], Train Loss: 23.8784, Val Loss: 38.8913\n",
      "Epoch [987/1000], Train Loss: 26.7760, Val Loss: 63.1430\n",
      "Epoch [988/1000], Train Loss: 32.1097, Val Loss: 35.9009\n",
      "Epoch [989/1000], Train Loss: 28.8898, Val Loss: 67.0646\n",
      "Epoch [990/1000], Train Loss: 34.3844, Val Loss: 44.0310\n",
      "Epoch [991/1000], Train Loss: 30.7700, Val Loss: 42.9184\n",
      "Epoch [992/1000], Train Loss: 41.3207, Val Loss: 51.4301\n",
      "Epoch [993/1000], Train Loss: 30.0117, Val Loss: 36.0375\n",
      "Epoch [994/1000], Train Loss: 29.8139, Val Loss: 34.9989\n",
      "Epoch [995/1000], Train Loss: 27.8693, Val Loss: 58.3546\n",
      "Epoch [996/1000], Train Loss: 52.0221, Val Loss: 42.7910\n",
      "Epoch [997/1000], Train Loss: 28.1575, Val Loss: 34.5837\n",
      "Epoch [998/1000], Train Loss: 62.9147, Val Loss: 36.8910\n",
      "Epoch [999/1000], Train Loss: 28.4107, Val Loss: 37.0316\n",
      "Epoch [1000/1000], Train Loss: 586.2846, Val Loss: 46.1979\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(586.2846372951932, 46.19793382432726)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 6.113522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.113521500311958"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.tester(Xtr,Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "hidden_size = 32\n",
    "num_layers = 2\n",
    "embedding_size=16\n",
    "model = RNNModel(input_size=13, hidden_size=hidden_size, num_layers=num_layers, output_size=1,embedding_size=embedding_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn=HelperClass(Xtr,Ytr,model,700,1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/700], Train Loss: 221493.3460, Val Loss: 223252.2124\n",
      "Epoch [2/700], Train Loss: 221413.1234, Val Loss: 223115.9306\n",
      "Epoch [3/700], Train Loss: 221020.6350, Val Loss: 222075.5210\n",
      "Epoch [4/700], Train Loss: 215493.1789, Val Loss: 204848.5256\n",
      "Epoch [5/700], Train Loss: 189426.0091, Val Loss: 179437.5590\n",
      "Epoch [6/700], Train Loss: 169027.8488, Val Loss: 159131.2914\n",
      "Epoch [7/700], Train Loss: 153937.2787, Val Loss: 147772.6387\n",
      "Epoch [8/700], Train Loss: 145050.8614, Val Loss: 140228.9461\n",
      "Epoch [9/700], Train Loss: 138429.5819, Val Loss: 134220.6450\n",
      "Epoch [10/700], Train Loss: 132908.4528, Val Loss: 129061.2911\n",
      "Epoch [11/700], Train Loss: 127846.4170, Val Loss: 124157.3218\n",
      "Epoch [12/700], Train Loss: 122932.1140, Val Loss: 119187.7784\n",
      "Epoch [13/700], Train Loss: 117910.0483, Val Loss: 114190.7513\n",
      "Epoch [14/700], Train Loss: 112689.8497, Val Loss: 108988.2426\n",
      "Epoch [15/700], Train Loss: 107267.4661, Val Loss: 103471.7440\n",
      "Epoch [16/700], Train Loss: 101695.3246, Val Loss: 98344.9313\n",
      "Epoch [17/700], Train Loss: 96782.4815, Val Loss: 94081.7691\n",
      "Epoch [18/700], Train Loss: 92696.4796, Val Loss: 90413.4982\n",
      "Epoch [19/700], Train Loss: 88820.5373, Val Loss: 86858.3491\n",
      "Epoch [20/700], Train Loss: 85397.2995, Val Loss: 83858.5271\n",
      "Epoch [21/700], Train Loss: 82484.9278, Val Loss: 81296.4622\n",
      "Epoch [22/700], Train Loss: 79985.5212, Val Loss: 78945.6804\n",
      "Epoch [23/700], Train Loss: 77577.5007, Val Loss: 76511.9968\n",
      "Epoch [24/700], Train Loss: 74998.6313, Val Loss: 73914.9919\n",
      "Epoch [25/700], Train Loss: 72293.9433, Val Loss: 71175.5769\n",
      "Epoch [26/700], Train Loss: 69414.7977, Val Loss: 68270.7110\n",
      "Epoch [27/700], Train Loss: 66490.0281, Val Loss: 65449.2483\n",
      "Epoch [28/700], Train Loss: 63743.9835, Val Loss: 62771.4621\n",
      "Epoch [29/700], Train Loss: 60912.8136, Val Loss: 59918.5372\n",
      "Epoch [30/700], Train Loss: 57467.9011, Val Loss: 55381.8838\n",
      "Epoch [31/700], Train Loss: 51626.3538, Val Loss: 49037.4223\n",
      "Epoch [32/700], Train Loss: 46636.7433, Val Loss: 46055.2943\n",
      "Epoch [33/700], Train Loss: 44596.5276, Val Loss: 44496.5207\n",
      "Epoch [34/700], Train Loss: 43357.9446, Val Loss: 43464.4716\n",
      "Epoch [35/700], Train Loss: 42490.8185, Val Loss: 42803.7338\n",
      "Epoch [36/700], Train Loss: 41947.4650, Val Loss: 42470.2280\n",
      "Epoch [37/700], Train Loss: 41492.4272, Val Loss: 42131.6947\n",
      "Epoch [38/700], Train Loss: 41111.6403, Val Loss: 41613.4169\n",
      "Epoch [39/700], Train Loss: 40691.2300, Val Loss: 41261.5459\n",
      "Epoch [40/700], Train Loss: 40352.1038, Val Loss: 40949.7710\n",
      "Epoch [41/700], Train Loss: 40184.8172, Val Loss: 40703.1491\n",
      "Epoch [42/700], Train Loss: 39829.7984, Val Loss: 40479.6036\n",
      "Epoch [43/700], Train Loss: 39587.7965, Val Loss: 40234.8551\n",
      "Epoch [44/700], Train Loss: 39354.0697, Val Loss: 40138.5258\n",
      "Epoch [45/700], Train Loss: 39161.1070, Val Loss: 39974.3251\n",
      "Epoch [46/700], Train Loss: 38944.3179, Val Loss: 39667.4459\n",
      "Epoch [47/700], Train Loss: 38736.1411, Val Loss: 39428.1998\n",
      "Epoch [48/700], Train Loss: 38516.4588, Val Loss: 39243.8230\n",
      "Epoch [49/700], Train Loss: 38274.4158, Val Loss: 39180.8501\n",
      "Epoch [50/700], Train Loss: 38110.0169, Val Loss: 38863.7118\n",
      "Epoch [51/700], Train Loss: 37941.3930, Val Loss: 38666.3856\n",
      "Epoch [52/700], Train Loss: 37707.5160, Val Loss: 38511.1978\n",
      "Epoch [53/700], Train Loss: 37526.4647, Val Loss: 38460.8162\n",
      "Epoch [54/700], Train Loss: 37367.2693, Val Loss: 38197.2715\n",
      "Epoch [55/700], Train Loss: 37172.7426, Val Loss: 37881.1210\n",
      "Epoch [56/700], Train Loss: 36959.7412, Val Loss: 37803.8240\n",
      "Epoch [57/700], Train Loss: 36800.8812, Val Loss: 37718.3898\n",
      "Epoch [58/700], Train Loss: 36600.1999, Val Loss: 37371.4629\n",
      "Epoch [59/700], Train Loss: 36406.1732, Val Loss: 37230.3874\n",
      "Epoch [60/700], Train Loss: 36242.2511, Val Loss: 36952.5099\n",
      "Epoch [61/700], Train Loss: 35985.4090, Val Loss: 36681.3051\n",
      "Epoch [62/700], Train Loss: 35749.1011, Val Loss: 36503.3080\n",
      "Epoch [63/700], Train Loss: 35584.2043, Val Loss: 36335.6894\n",
      "Epoch [64/700], Train Loss: 35336.9521, Val Loss: 36102.5449\n",
      "Epoch [65/700], Train Loss: 35117.6427, Val Loss: 35823.8401\n",
      "Epoch [66/700], Train Loss: 34877.7353, Val Loss: 35501.9746\n",
      "Epoch [67/700], Train Loss: 34629.1614, Val Loss: 35270.3465\n",
      "Epoch [68/700], Train Loss: 34355.1346, Val Loss: 35072.0071\n",
      "Epoch [69/700], Train Loss: 34150.0487, Val Loss: 34988.0901\n",
      "Epoch [70/700], Train Loss: 33912.3866, Val Loss: 34625.4323\n",
      "Epoch [71/700], Train Loss: 33674.5194, Val Loss: 34409.3656\n",
      "Epoch [72/700], Train Loss: 33442.0483, Val Loss: 34206.7499\n",
      "Epoch [73/700], Train Loss: 33316.6092, Val Loss: 33955.7158\n",
      "Epoch [74/700], Train Loss: 32984.0895, Val Loss: 34026.1958\n",
      "Epoch [75/700], Train Loss: 32758.8744, Val Loss: 33508.0902\n",
      "Epoch [76/700], Train Loss: 32569.6581, Val Loss: 33267.7024\n",
      "Epoch [77/700], Train Loss: 32384.2297, Val Loss: 33113.6472\n",
      "Epoch [78/700], Train Loss: 32122.5083, Val Loss: 32861.8235\n",
      "Epoch [79/700], Train Loss: 31889.8719, Val Loss: 32640.2591\n",
      "Epoch [80/700], Train Loss: 31638.7239, Val Loss: 32344.5017\n",
      "Epoch [81/700], Train Loss: 31437.5305, Val Loss: 32167.2896\n",
      "Epoch [82/700], Train Loss: 31230.8837, Val Loss: 31999.9045\n",
      "Epoch [83/700], Train Loss: 31017.9111, Val Loss: 31681.2712\n",
      "Epoch [84/700], Train Loss: 30772.5348, Val Loss: 31437.6691\n",
      "Epoch [85/700], Train Loss: 30532.4792, Val Loss: 31236.6699\n",
      "Epoch [86/700], Train Loss: 30273.8287, Val Loss: 30995.4279\n",
      "Epoch [87/700], Train Loss: 30057.5834, Val Loss: 30735.2997\n",
      "Epoch [88/700], Train Loss: 29833.2458, Val Loss: 30496.8363\n",
      "Epoch [89/700], Train Loss: 29507.0832, Val Loss: 30069.5176\n",
      "Epoch [90/700], Train Loss: 29278.1507, Val Loss: 29944.2892\n",
      "Epoch [91/700], Train Loss: 28979.0943, Val Loss: 29591.4127\n",
      "Epoch [92/700], Train Loss: 28709.2413, Val Loss: 29437.1221\n",
      "Epoch [93/700], Train Loss: 28503.0803, Val Loss: 29102.4163\n",
      "Epoch [94/700], Train Loss: 28243.6986, Val Loss: 28867.2579\n",
      "Epoch [95/700], Train Loss: 27989.3245, Val Loss: 28794.9061\n",
      "Epoch [96/700], Train Loss: 27745.5834, Val Loss: 28459.1226\n",
      "Epoch [97/700], Train Loss: 27521.2942, Val Loss: 28124.5035\n",
      "Epoch [98/700], Train Loss: 27293.0042, Val Loss: 27964.1159\n",
      "Epoch [99/700], Train Loss: 27113.8653, Val Loss: 27625.5460\n",
      "Epoch [100/700], Train Loss: 26798.9622, Val Loss: 27426.3458\n",
      "Epoch [101/700], Train Loss: 26565.9043, Val Loss: 27235.5757\n",
      "Epoch [102/700], Train Loss: 26383.9867, Val Loss: 27049.1523\n",
      "Epoch [103/700], Train Loss: 26133.1161, Val Loss: 26693.4895\n",
      "Epoch [104/700], Train Loss: 25893.4224, Val Loss: 26423.1712\n",
      "Epoch [105/700], Train Loss: 25682.3919, Val Loss: 26209.3796\n",
      "Epoch [106/700], Train Loss: 25441.7684, Val Loss: 25924.1031\n",
      "Epoch [107/700], Train Loss: 25213.0201, Val Loss: 25736.1697\n",
      "Epoch [108/700], Train Loss: 24988.1418, Val Loss: 25466.0099\n",
      "Epoch [109/700], Train Loss: 24762.8336, Val Loss: 25522.3414\n",
      "Epoch [110/700], Train Loss: 24565.4546, Val Loss: 25220.3072\n",
      "Epoch [111/700], Train Loss: 24294.4239, Val Loss: 24742.7047\n",
      "Epoch [112/700], Train Loss: 24051.2570, Val Loss: 24666.4079\n",
      "Epoch [113/700], Train Loss: 23893.8607, Val Loss: 24386.7701\n",
      "Epoch [114/700], Train Loss: 23558.9228, Val Loss: 24004.5517\n",
      "Epoch [115/700], Train Loss: 23340.9941, Val Loss: 23704.8025\n",
      "Epoch [116/700], Train Loss: 23052.1307, Val Loss: 23539.1111\n",
      "Epoch [117/700], Train Loss: 22846.8298, Val Loss: 23267.2908\n",
      "Epoch [118/700], Train Loss: 22660.6920, Val Loss: 22959.3122\n",
      "Epoch [119/700], Train Loss: 22387.2191, Val Loss: 22900.0956\n",
      "Epoch [120/700], Train Loss: 22215.4013, Val Loss: 22711.7878\n",
      "Epoch [121/700], Train Loss: 21887.9596, Val Loss: 22213.8618\n",
      "Epoch [122/700], Train Loss: 21584.6454, Val Loss: 21949.4381\n",
      "Epoch [123/700], Train Loss: 21379.1117, Val Loss: 21681.0667\n",
      "Epoch [124/700], Train Loss: 21090.5882, Val Loss: 21418.6532\n",
      "Epoch [125/700], Train Loss: 20846.6791, Val Loss: 21160.9409\n",
      "Epoch [126/700], Train Loss: 20553.2178, Val Loss: 20891.1007\n",
      "Epoch [127/700], Train Loss: 20254.2459, Val Loss: 20996.1181\n",
      "Epoch [128/700], Train Loss: 19957.6605, Val Loss: 20197.9499\n",
      "Epoch [129/700], Train Loss: 19719.1391, Val Loss: 19891.0448\n",
      "Epoch [130/700], Train Loss: 19344.9733, Val Loss: 19621.5497\n",
      "Epoch [131/700], Train Loss: 19078.5686, Val Loss: 19271.5384\n",
      "Epoch [132/700], Train Loss: 18758.8703, Val Loss: 18969.1238\n",
      "Epoch [133/700], Train Loss: 18442.9405, Val Loss: 18793.9007\n",
      "Epoch [134/700], Train Loss: 18128.8475, Val Loss: 18382.6341\n",
      "Epoch [135/700], Train Loss: 17845.8178, Val Loss: 18100.6118\n",
      "Epoch [136/700], Train Loss: 17516.1151, Val Loss: 17697.6835\n",
      "Epoch [137/700], Train Loss: 17233.1767, Val Loss: 17395.1149\n",
      "Epoch [138/700], Train Loss: 16928.9621, Val Loss: 17067.1860\n",
      "Epoch [139/700], Train Loss: 16628.2748, Val Loss: 16778.0530\n",
      "Epoch [140/700], Train Loss: 16372.7090, Val Loss: 16485.9421\n",
      "Epoch [141/700], Train Loss: 16020.5621, Val Loss: 16130.7757\n",
      "Epoch [142/700], Train Loss: 15730.9117, Val Loss: 15884.6934\n",
      "Epoch [143/700], Train Loss: 15402.8265, Val Loss: 15597.6795\n",
      "Epoch [144/700], Train Loss: 15081.0556, Val Loss: 15241.4519\n",
      "Epoch [145/700], Train Loss: 14797.2153, Val Loss: 14998.5047\n",
      "Epoch [146/700], Train Loss: 14568.1636, Val Loss: 14647.1087\n",
      "Epoch [147/700], Train Loss: 14203.4644, Val Loss: 14387.4565\n",
      "Epoch [148/700], Train Loss: 13894.1902, Val Loss: 14050.1725\n",
      "Epoch [149/700], Train Loss: 13592.1192, Val Loss: 13686.0864\n",
      "Epoch [150/700], Train Loss: 13295.6532, Val Loss: 13541.1157\n",
      "Epoch [151/700], Train Loss: 13014.5436, Val Loss: 13404.2031\n",
      "Epoch [152/700], Train Loss: 12735.4250, Val Loss: 12958.6034\n",
      "Epoch [153/700], Train Loss: 12444.9283, Val Loss: 12528.8205\n",
      "Epoch [154/700], Train Loss: 12143.2393, Val Loss: 12243.9199\n",
      "Epoch [155/700], Train Loss: 11894.8227, Val Loss: 11992.8308\n",
      "Epoch [156/700], Train Loss: 11587.2512, Val Loss: 11879.5227\n",
      "Epoch [157/700], Train Loss: 11337.5519, Val Loss: 11437.1566\n",
      "Epoch [158/700], Train Loss: 11137.9847, Val Loss: 11168.5065\n",
      "Epoch [159/700], Train Loss: 10799.5148, Val Loss: 11035.4239\n",
      "Epoch [160/700], Train Loss: 10544.0002, Val Loss: 10715.6620\n",
      "Epoch [161/700], Train Loss: 10303.3426, Val Loss: 10465.2675\n",
      "Epoch [162/700], Train Loss: 10090.7348, Val Loss: 10166.3085\n",
      "Epoch [163/700], Train Loss: 9839.2122, Val Loss: 9922.8605\n",
      "Epoch [164/700], Train Loss: 9586.1758, Val Loss: 9949.9969\n",
      "Epoch [165/700], Train Loss: 9356.5073, Val Loss: 9498.1764\n",
      "Epoch [166/700], Train Loss: 9106.8668, Val Loss: 9219.1064\n",
      "Epoch [167/700], Train Loss: 8886.2207, Val Loss: 9010.9670\n",
      "Epoch [168/700], Train Loss: 8657.7234, Val Loss: 8725.1100\n",
      "Epoch [169/700], Train Loss: 8393.7238, Val Loss: 8551.2634\n",
      "Epoch [170/700], Train Loss: 8117.1421, Val Loss: 8263.1195\n",
      "Epoch [171/700], Train Loss: 7876.9008, Val Loss: 7983.2773\n",
      "Epoch [172/700], Train Loss: 7659.8345, Val Loss: 7662.9335\n",
      "Epoch [173/700], Train Loss: 7421.1591, Val Loss: 7571.6429\n",
      "Epoch [174/700], Train Loss: 7244.6468, Val Loss: 7283.0743\n",
      "Epoch [175/700], Train Loss: 7056.9152, Val Loss: 7138.6771\n",
      "Epoch [176/700], Train Loss: 6830.9753, Val Loss: 6847.2113\n",
      "Epoch [177/700], Train Loss: 6649.4111, Val Loss: 6645.0465\n",
      "Epoch [178/700], Train Loss: 6491.4717, Val Loss: 6512.0624\n",
      "Epoch [179/700], Train Loss: 6320.3958, Val Loss: 6300.8912\n",
      "Epoch [180/700], Train Loss: 6165.5156, Val Loss: 6153.7517\n",
      "Epoch [181/700], Train Loss: 6017.1089, Val Loss: 5982.8064\n",
      "Epoch [182/700], Train Loss: 5843.7463, Val Loss: 5856.3775\n",
      "Epoch [183/700], Train Loss: 5693.0874, Val Loss: 5734.7576\n",
      "Epoch [184/700], Train Loss: 5565.2587, Val Loss: 5553.4749\n",
      "Epoch [185/700], Train Loss: 5443.4020, Val Loss: 5518.2765\n",
      "Epoch [186/700], Train Loss: 5290.5691, Val Loss: 5330.4064\n",
      "Epoch [187/700], Train Loss: 5181.2942, Val Loss: 5211.9527\n",
      "Epoch [188/700], Train Loss: 5040.2916, Val Loss: 5033.6187\n",
      "Epoch [189/700], Train Loss: 4918.6504, Val Loss: 4961.4187\n",
      "Epoch [190/700], Train Loss: 4818.4325, Val Loss: 4861.8165\n",
      "Epoch [191/700], Train Loss: 4727.8712, Val Loss: 4730.9529\n",
      "Epoch [192/700], Train Loss: 4611.2718, Val Loss: 4587.3996\n",
      "Epoch [193/700], Train Loss: 4507.5669, Val Loss: 4697.8196\n",
      "Epoch [194/700], Train Loss: 4454.7101, Val Loss: 4396.8481\n",
      "Epoch [195/700], Train Loss: 4321.7032, Val Loss: 4328.7631\n",
      "Epoch [196/700], Train Loss: 4233.8839, Val Loss: 4235.8462\n",
      "Epoch [197/700], Train Loss: 4135.5173, Val Loss: 4122.0622\n",
      "Epoch [198/700], Train Loss: 4095.1393, Val Loss: 4112.6429\n",
      "Epoch [199/700], Train Loss: 3997.1410, Val Loss: 4057.2938\n",
      "Epoch [200/700], Train Loss: 3916.9629, Val Loss: 3938.1326\n",
      "Epoch [201/700], Train Loss: 3832.2071, Val Loss: 3865.6318\n",
      "Epoch [202/700], Train Loss: 3744.0556, Val Loss: 3754.0057\n",
      "Epoch [203/700], Train Loss: 3742.6140, Val Loss: 3644.7138\n",
      "Epoch [204/700], Train Loss: 3616.4479, Val Loss: 3583.9308\n",
      "Epoch [205/700], Train Loss: 3570.1186, Val Loss: 3611.5534\n",
      "Epoch [206/700], Train Loss: 3477.2971, Val Loss: 3516.8635\n",
      "Epoch [207/700], Train Loss: 3416.6019, Val Loss: 3529.6369\n",
      "Epoch [208/700], Train Loss: 3357.4682, Val Loss: 3354.7117\n",
      "Epoch [209/700], Train Loss: 3283.0095, Val Loss: 3284.5775\n",
      "Epoch [210/700], Train Loss: 3224.3780, Val Loss: 3264.7335\n",
      "Epoch [211/700], Train Loss: 3174.6055, Val Loss: 3287.0381\n",
      "Epoch [212/700], Train Loss: 3107.6908, Val Loss: 3109.3787\n",
      "Epoch [213/700], Train Loss: 3060.0383, Val Loss: 3125.1586\n",
      "Epoch [214/700], Train Loss: 3008.6656, Val Loss: 2982.7871\n",
      "Epoch [215/700], Train Loss: 2944.8267, Val Loss: 2957.4087\n",
      "Epoch [216/700], Train Loss: 2918.4037, Val Loss: 2907.9815\n",
      "Epoch [217/700], Train Loss: 2846.5268, Val Loss: 2877.1552\n",
      "Epoch [218/700], Train Loss: 2795.0648, Val Loss: 2784.0092\n",
      "Epoch [219/700], Train Loss: 2738.6750, Val Loss: 2744.3904\n",
      "Epoch [220/700], Train Loss: 2699.5932, Val Loss: 2781.7397\n",
      "Epoch [221/700], Train Loss: 2678.4952, Val Loss: 2650.4684\n",
      "Epoch [222/700], Train Loss: 2639.6686, Val Loss: 2611.1601\n",
      "Epoch [223/700], Train Loss: 2569.1158, Val Loss: 2587.1055\n",
      "Epoch [224/700], Train Loss: 2526.3290, Val Loss: 2529.0591\n",
      "Epoch [225/700], Train Loss: 2487.8040, Val Loss: 2488.0456\n",
      "Epoch [226/700], Train Loss: 2432.4322, Val Loss: 2451.5892\n",
      "Epoch [227/700], Train Loss: 2396.2511, Val Loss: 2385.5461\n",
      "Epoch [228/700], Train Loss: 2354.1313, Val Loss: 2362.7291\n",
      "Epoch [229/700], Train Loss: 2320.3976, Val Loss: 2399.6825\n",
      "Epoch [230/700], Train Loss: 2275.2999, Val Loss: 2262.2340\n",
      "Epoch [231/700], Train Loss: 2241.0149, Val Loss: 2216.8027\n",
      "Epoch [232/700], Train Loss: 2204.7347, Val Loss: 2179.8179\n",
      "Epoch [233/700], Train Loss: 2165.2875, Val Loss: 2136.0479\n",
      "Epoch [234/700], Train Loss: 2128.5090, Val Loss: 2151.5406\n",
      "Epoch [235/700], Train Loss: 2124.6958, Val Loss: 2068.4898\n",
      "Epoch [236/700], Train Loss: 2046.6840, Val Loss: 2036.9254\n",
      "Epoch [237/700], Train Loss: 2071.8983, Val Loss: 2109.3241\n",
      "Epoch [238/700], Train Loss: 2012.6844, Val Loss: 1974.4314\n",
      "Epoch [239/700], Train Loss: 2004.9725, Val Loss: 1964.6146\n",
      "Epoch [240/700], Train Loss: 1938.0161, Val Loss: 1918.6686\n",
      "Epoch [241/700], Train Loss: 1918.6162, Val Loss: 1880.9833\n",
      "Epoch [242/700], Train Loss: 1885.6101, Val Loss: 1867.6091\n",
      "Epoch [243/700], Train Loss: 1854.9894, Val Loss: 1859.1502\n",
      "Epoch [244/700], Train Loss: 1823.5948, Val Loss: 1829.9718\n",
      "Epoch [245/700], Train Loss: 1812.9429, Val Loss: 1852.1577\n",
      "Epoch [246/700], Train Loss: 1790.9760, Val Loss: 1775.1214\n",
      "Epoch [247/700], Train Loss: 1759.2772, Val Loss: 1819.7366\n",
      "Epoch [248/700], Train Loss: 1741.4522, Val Loss: 1735.2168\n",
      "Epoch [249/700], Train Loss: 1720.2376, Val Loss: 1757.6947\n",
      "Epoch [250/700], Train Loss: 1689.1223, Val Loss: 1721.5288\n",
      "Epoch [251/700], Train Loss: 1724.3186, Val Loss: 1671.0104\n",
      "Epoch [252/700], Train Loss: 1649.2899, Val Loss: 1660.2837\n",
      "Epoch [253/700], Train Loss: 1637.8560, Val Loss: 1643.9824\n",
      "Epoch [254/700], Train Loss: 1610.1223, Val Loss: 1605.0702\n",
      "Epoch [255/700], Train Loss: 1587.5635, Val Loss: 1584.4921\n",
      "Epoch [256/700], Train Loss: 1571.1269, Val Loss: 1606.6272\n",
      "Epoch [257/700], Train Loss: 1558.0394, Val Loss: 1656.7541\n",
      "Epoch [258/700], Train Loss: 1545.4150, Val Loss: 1654.6843\n",
      "Epoch [259/700], Train Loss: 1543.8792, Val Loss: 1511.6716\n",
      "Epoch [260/700], Train Loss: 1512.0885, Val Loss: 1517.7499\n",
      "Epoch [261/700], Train Loss: 1488.4849, Val Loss: 1486.7202\n",
      "Epoch [262/700], Train Loss: 1463.7874, Val Loss: 1464.6730\n",
      "Epoch [263/700], Train Loss: 1476.4196, Val Loss: 1550.5745\n",
      "Epoch [264/700], Train Loss: 1447.7501, Val Loss: 1455.2961\n",
      "Epoch [265/700], Train Loss: 1428.3028, Val Loss: 1444.1468\n",
      "Epoch [266/700], Train Loss: 1410.7427, Val Loss: 1483.6971\n",
      "Epoch [267/700], Train Loss: 1393.7965, Val Loss: 1386.0831\n",
      "Epoch [268/700], Train Loss: 1383.9530, Val Loss: 1372.2780\n",
      "Epoch [269/700], Train Loss: 1375.2097, Val Loss: 1378.5750\n",
      "Epoch [270/700], Train Loss: 1361.4641, Val Loss: 1372.1926\n",
      "Epoch [271/700], Train Loss: 1345.0457, Val Loss: 1384.9728\n",
      "Epoch [272/700], Train Loss: 1335.8513, Val Loss: 1393.0205\n",
      "Epoch [273/700], Train Loss: 1325.8792, Val Loss: 1303.4236\n",
      "Epoch [274/700], Train Loss: 1306.7941, Val Loss: 1299.3857\n",
      "Epoch [275/700], Train Loss: 1295.5173, Val Loss: 1282.1120\n",
      "Epoch [276/700], Train Loss: 1279.5070, Val Loss: 1292.4541\n",
      "Epoch [277/700], Train Loss: 1264.6711, Val Loss: 1261.8145\n",
      "Epoch [278/700], Train Loss: 1266.1827, Val Loss: 1248.3750\n",
      "Epoch [279/700], Train Loss: 1235.7464, Val Loss: 1250.5329\n",
      "Epoch [280/700], Train Loss: 1235.1341, Val Loss: 1232.5734\n",
      "Epoch [281/700], Train Loss: 1219.4613, Val Loss: 1223.5158\n",
      "Epoch [282/700], Train Loss: 1202.8123, Val Loss: 1218.1426\n",
      "Epoch [283/700], Train Loss: 1192.3395, Val Loss: 1200.8404\n",
      "Epoch [284/700], Train Loss: 1189.7128, Val Loss: 1189.3857\n",
      "Epoch [285/700], Train Loss: 1165.7434, Val Loss: 1219.9186\n",
      "Epoch [286/700], Train Loss: 1171.0140, Val Loss: 1169.7921\n",
      "Epoch [287/700], Train Loss: 1158.6287, Val Loss: 1248.9308\n",
      "Epoch [288/700], Train Loss: 1160.3972, Val Loss: 1154.7581\n",
      "Epoch [289/700], Train Loss: 1132.6897, Val Loss: 1155.7613\n",
      "Epoch [290/700], Train Loss: 1120.5425, Val Loss: 1142.8277\n",
      "Epoch [291/700], Train Loss: 1110.2857, Val Loss: 1167.3754\n",
      "Epoch [292/700], Train Loss: 1109.1304, Val Loss: 1127.4845\n",
      "Epoch [293/700], Train Loss: 1107.4075, Val Loss: 1124.1473\n",
      "Epoch [294/700], Train Loss: 1093.3349, Val Loss: 1097.2161\n",
      "Epoch [295/700], Train Loss: 1071.5289, Val Loss: 1079.9856\n",
      "Epoch [296/700], Train Loss: 1066.6398, Val Loss: 1075.0721\n",
      "Epoch [297/700], Train Loss: 1074.9707, Val Loss: 1069.6329\n",
      "Epoch [298/700], Train Loss: 1055.5027, Val Loss: 1059.6369\n",
      "Epoch [299/700], Train Loss: 1033.4649, Val Loss: 1064.3560\n",
      "Epoch [300/700], Train Loss: 1038.3960, Val Loss: 1068.6407\n",
      "Epoch [301/700], Train Loss: 1025.2129, Val Loss: 1065.8992\n",
      "Epoch [302/700], Train Loss: 1018.3678, Val Loss: 1086.8242\n",
      "Epoch [303/700], Train Loss: 1003.9389, Val Loss: 1093.3382\n",
      "Epoch [304/700], Train Loss: 1012.6621, Val Loss: 1002.1667\n",
      "Epoch [305/700], Train Loss: 987.9164, Val Loss: 998.5803\n",
      "Epoch [306/700], Train Loss: 981.7987, Val Loss: 1000.2817\n",
      "Epoch [307/700], Train Loss: 969.9544, Val Loss: 1046.3263\n",
      "Epoch [308/700], Train Loss: 973.2919, Val Loss: 976.7001\n",
      "Epoch [309/700], Train Loss: 959.3037, Val Loss: 972.7340\n",
      "Epoch [310/700], Train Loss: 961.5102, Val Loss: 960.9174\n",
      "Epoch [311/700], Train Loss: 943.1493, Val Loss: 992.4273\n",
      "Epoch [312/700], Train Loss: 944.6452, Val Loss: 954.2904\n",
      "Epoch [313/700], Train Loss: 934.9351, Val Loss: 1004.5486\n",
      "Epoch [314/700], Train Loss: 941.8392, Val Loss: 929.1098\n",
      "Epoch [315/700], Train Loss: 918.2228, Val Loss: 965.1961\n",
      "Epoch [316/700], Train Loss: 929.6128, Val Loss: 925.2379\n",
      "Epoch [317/700], Train Loss: 907.3003, Val Loss: 913.2383\n",
      "Epoch [318/700], Train Loss: 910.2437, Val Loss: 906.8987\n",
      "Epoch [319/700], Train Loss: 900.1076, Val Loss: 904.3629\n",
      "Epoch [320/700], Train Loss: 888.0796, Val Loss: 895.9642\n",
      "Epoch [321/700], Train Loss: 885.7022, Val Loss: 888.1303\n",
      "Epoch [322/700], Train Loss: 877.6201, Val Loss: 890.4482\n",
      "Epoch [323/700], Train Loss: 879.1512, Val Loss: 881.7073\n",
      "Epoch [324/700], Train Loss: 862.9745, Val Loss: 877.9046\n",
      "Epoch [325/700], Train Loss: 865.0793, Val Loss: 1029.5446\n",
      "Epoch [326/700], Train Loss: 869.1406, Val Loss: 876.9633\n",
      "Epoch [327/700], Train Loss: 866.7828, Val Loss: 857.6857\n",
      "Epoch [328/700], Train Loss: 861.6567, Val Loss: 861.8051\n",
      "Epoch [329/700], Train Loss: 835.6423, Val Loss: 888.7342\n",
      "Epoch [330/700], Train Loss: 840.4849, Val Loss: 895.1463\n",
      "Epoch [331/700], Train Loss: 836.3754, Val Loss: 836.2590\n",
      "Epoch [332/700], Train Loss: 826.2150, Val Loss: 833.3959\n",
      "Epoch [333/700], Train Loss: 817.9543, Val Loss: 834.0896\n",
      "Epoch [334/700], Train Loss: 820.8689, Val Loss: 827.3184\n",
      "Epoch [335/700], Train Loss: 825.3373, Val Loss: 875.8626\n",
      "Epoch [336/700], Train Loss: 812.0413, Val Loss: 810.8708\n",
      "Epoch [337/700], Train Loss: 801.7828, Val Loss: 811.3181\n",
      "Epoch [338/700], Train Loss: 802.4411, Val Loss: 823.0319\n",
      "Epoch [339/700], Train Loss: 801.8848, Val Loss: 812.7571\n",
      "Epoch [340/700], Train Loss: 784.0791, Val Loss: 803.9467\n",
      "Epoch [341/700], Train Loss: 781.4289, Val Loss: 808.6026\n",
      "Epoch [342/700], Train Loss: 772.7381, Val Loss: 793.2786\n",
      "Epoch [343/700], Train Loss: 798.4060, Val Loss: 780.2357\n",
      "Epoch [344/700], Train Loss: 767.0325, Val Loss: 794.6349\n",
      "Epoch [345/700], Train Loss: 771.2803, Val Loss: 788.3568\n",
      "Epoch [346/700], Train Loss: 765.4941, Val Loss: 807.5383\n",
      "Epoch [347/700], Train Loss: 754.0210, Val Loss: 774.3897\n",
      "Epoch [348/700], Train Loss: 752.7375, Val Loss: 777.4142\n",
      "Epoch [349/700], Train Loss: 749.3737, Val Loss: 755.0035\n",
      "Epoch [350/700], Train Loss: 749.5859, Val Loss: 752.3703\n",
      "Epoch [351/700], Train Loss: 748.7299, Val Loss: 755.7788\n",
      "Epoch [352/700], Train Loss: 742.2919, Val Loss: 742.0084\n",
      "Epoch [353/700], Train Loss: 733.7114, Val Loss: 755.6051\n",
      "Epoch [354/700], Train Loss: 739.2666, Val Loss: 755.2792\n",
      "Epoch [355/700], Train Loss: 734.1631, Val Loss: 750.8764\n",
      "Epoch [356/700], Train Loss: 726.0534, Val Loss: 729.1734\n",
      "Epoch [357/700], Train Loss: 713.9781, Val Loss: 752.9630\n",
      "Epoch [358/700], Train Loss: 716.1120, Val Loss: 737.1183\n",
      "Epoch [359/700], Train Loss: 714.0051, Val Loss: 797.9599\n",
      "Epoch [360/700], Train Loss: 716.8115, Val Loss: 768.4545\n",
      "Epoch [361/700], Train Loss: 709.5059, Val Loss: 715.8192\n",
      "Epoch [362/700], Train Loss: 718.4941, Val Loss: 712.7371\n",
      "Epoch [363/700], Train Loss: 690.5150, Val Loss: 706.3165\n",
      "Epoch [364/700], Train Loss: 693.7904, Val Loss: 720.9737\n",
      "Epoch [365/700], Train Loss: 691.2602, Val Loss: 709.8024\n",
      "Epoch [366/700], Train Loss: 706.1939, Val Loss: 708.7721\n",
      "Epoch [367/700], Train Loss: 688.7386, Val Loss: 698.4506\n",
      "Epoch [368/700], Train Loss: 684.7375, Val Loss: 694.9000\n",
      "Epoch [369/700], Train Loss: 683.5989, Val Loss: 768.2094\n",
      "Epoch [370/700], Train Loss: 687.0290, Val Loss: 706.5627\n",
      "Epoch [371/700], Train Loss: 682.3121, Val Loss: 742.6471\n",
      "Epoch [372/700], Train Loss: 679.6476, Val Loss: 700.7546\n",
      "Epoch [373/700], Train Loss: 681.2878, Val Loss: 678.5741\n",
      "Epoch [374/700], Train Loss: 664.5318, Val Loss: 678.1600\n",
      "Epoch [375/700], Train Loss: 668.5871, Val Loss: 682.1942\n",
      "Epoch [376/700], Train Loss: 671.1120, Val Loss: 678.9712\n",
      "Epoch [377/700], Train Loss: 664.4469, Val Loss: 727.2788\n",
      "Epoch [378/700], Train Loss: 648.0914, Val Loss: 668.9502\n",
      "Epoch [379/700], Train Loss: 653.0557, Val Loss: 692.6610\n",
      "Epoch [380/700], Train Loss: 649.6935, Val Loss: 663.6952\n",
      "Epoch [381/700], Train Loss: 642.3432, Val Loss: 666.4490\n",
      "Epoch [382/700], Train Loss: 644.6147, Val Loss: 661.3713\n",
      "Epoch [383/700], Train Loss: 636.1686, Val Loss: 647.5670\n",
      "Epoch [384/700], Train Loss: 652.3224, Val Loss: 650.5371\n",
      "Epoch [385/700], Train Loss: 638.6816, Val Loss: 673.3120\n",
      "Epoch [386/700], Train Loss: 636.4073, Val Loss: 691.0435\n",
      "Epoch [387/700], Train Loss: 628.2081, Val Loss: 657.0170\n",
      "Epoch [388/700], Train Loss: 632.5050, Val Loss: 641.0765\n",
      "Epoch [389/700], Train Loss: 634.5106, Val Loss: 632.6007\n",
      "Epoch [390/700], Train Loss: 642.8650, Val Loss: 711.7728\n",
      "Epoch [391/700], Train Loss: 630.8042, Val Loss: 630.4372\n",
      "Epoch [392/700], Train Loss: 618.7317, Val Loss: 654.5303\n",
      "Epoch [393/700], Train Loss: 619.6807, Val Loss: 652.8004\n",
      "Epoch [394/700], Train Loss: 620.5155, Val Loss: 624.2821\n",
      "Epoch [395/700], Train Loss: 616.6214, Val Loss: 623.1382\n",
      "Epoch [396/700], Train Loss: 609.3306, Val Loss: 627.0372\n",
      "Epoch [397/700], Train Loss: 607.7831, Val Loss: 620.3876\n",
      "Epoch [398/700], Train Loss: 601.9177, Val Loss: 616.5655\n",
      "Epoch [399/700], Train Loss: 604.2254, Val Loss: 615.2296\n",
      "Epoch [400/700], Train Loss: 606.4213, Val Loss: 612.4246\n",
      "Epoch [401/700], Train Loss: 602.7519, Val Loss: 623.8642\n",
      "Epoch [402/700], Train Loss: 597.4286, Val Loss: 605.4436\n",
      "Epoch [403/700], Train Loss: 618.4446, Val Loss: 616.6960\n",
      "Epoch [404/700], Train Loss: 592.6642, Val Loss: 600.8874\n",
      "Epoch [405/700], Train Loss: 593.9456, Val Loss: 624.3500\n",
      "Epoch [406/700], Train Loss: 597.0789, Val Loss: 603.6432\n",
      "Epoch [407/700], Train Loss: 579.6928, Val Loss: 631.3649\n",
      "Epoch [408/700], Train Loss: 595.4900, Val Loss: 592.3818\n",
      "Epoch [409/700], Train Loss: 576.4250, Val Loss: 593.4064\n",
      "Epoch [410/700], Train Loss: 579.9170, Val Loss: 596.6060\n",
      "Epoch [411/700], Train Loss: 578.7488, Val Loss: 638.8030\n",
      "Epoch [412/700], Train Loss: 570.1068, Val Loss: 584.8019\n",
      "Epoch [413/700], Train Loss: 571.6209, Val Loss: 590.5154\n",
      "Epoch [414/700], Train Loss: 576.7044, Val Loss: 586.6910\n",
      "Epoch [415/700], Train Loss: 563.6599, Val Loss: 578.7197\n",
      "Epoch [416/700], Train Loss: 576.3416, Val Loss: 579.0527\n",
      "Epoch [417/700], Train Loss: 573.7345, Val Loss: 577.3473\n",
      "Epoch [418/700], Train Loss: 568.4779, Val Loss: 572.5974\n",
      "Epoch [419/700], Train Loss: 562.9571, Val Loss: 571.4047\n",
      "Epoch [420/700], Train Loss: 566.4813, Val Loss: 567.3131\n",
      "Epoch [421/700], Train Loss: 566.4073, Val Loss: 571.1036\n",
      "Epoch [422/700], Train Loss: 559.8721, Val Loss: 567.9518\n",
      "Epoch [423/700], Train Loss: 547.9469, Val Loss: 560.2375\n",
      "Epoch [424/700], Train Loss: 548.5895, Val Loss: 561.5050\n",
      "Epoch [425/700], Train Loss: 550.3624, Val Loss: 607.0395\n",
      "Epoch [426/700], Train Loss: 551.8149, Val Loss: 591.3255\n",
      "Epoch [427/700], Train Loss: 549.6956, Val Loss: 607.7040\n",
      "Epoch [428/700], Train Loss: 546.7145, Val Loss: 549.0636\n",
      "Epoch [429/700], Train Loss: 545.6606, Val Loss: 554.8225\n",
      "Epoch [430/700], Train Loss: 552.7584, Val Loss: 575.6851\n",
      "Epoch [431/700], Train Loss: 542.7220, Val Loss: 550.5681\n",
      "Epoch [432/700], Train Loss: 534.5741, Val Loss: 574.1818\n",
      "Epoch [433/700], Train Loss: 540.7880, Val Loss: 639.4244\n",
      "Epoch [434/700], Train Loss: 534.4833, Val Loss: 552.6542\n",
      "Epoch [435/700], Train Loss: 533.8133, Val Loss: 554.5030\n",
      "Epoch [436/700], Train Loss: 532.6187, Val Loss: 582.6351\n",
      "Epoch [437/700], Train Loss: 535.3755, Val Loss: 536.6667\n",
      "Epoch [438/700], Train Loss: 523.4507, Val Loss: 595.7984\n",
      "Epoch [439/700], Train Loss: 531.2729, Val Loss: 597.8616\n",
      "Epoch [440/700], Train Loss: 521.5859, Val Loss: 536.5058\n",
      "Epoch [441/700], Train Loss: 520.8982, Val Loss: 569.3132\n",
      "Epoch [442/700], Train Loss: 528.6698, Val Loss: 524.8087\n",
      "Epoch [443/700], Train Loss: 518.2957, Val Loss: 537.3402\n",
      "Epoch [444/700], Train Loss: 530.6737, Val Loss: 533.7848\n",
      "Epoch [445/700], Train Loss: 514.0782, Val Loss: 529.7774\n",
      "Epoch [446/700], Train Loss: 514.6219, Val Loss: 523.2603\n",
      "Epoch [447/700], Train Loss: 513.6243, Val Loss: 521.6898\n",
      "Epoch [448/700], Train Loss: 515.5164, Val Loss: 536.6124\n",
      "Epoch [449/700], Train Loss: 520.6650, Val Loss: 555.9650\n",
      "Epoch [450/700], Train Loss: 515.0089, Val Loss: 511.6627\n",
      "Epoch [451/700], Train Loss: 506.9309, Val Loss: 516.4932\n",
      "Epoch [452/700], Train Loss: 510.3535, Val Loss: 555.3944\n",
      "Epoch [453/700], Train Loss: 508.2853, Val Loss: 531.2542\n",
      "Epoch [454/700], Train Loss: 506.5522, Val Loss: 533.5605\n",
      "Epoch [455/700], Train Loss: 498.5904, Val Loss: 508.3348\n",
      "Epoch [456/700], Train Loss: 509.3202, Val Loss: 507.4739\n",
      "Epoch [457/700], Train Loss: 494.3049, Val Loss: 512.1406\n",
      "Epoch [458/700], Train Loss: 497.4897, Val Loss: 516.6458\n",
      "Epoch [459/700], Train Loss: 491.5912, Val Loss: 496.2752\n",
      "Epoch [460/700], Train Loss: 489.1414, Val Loss: 507.7384\n",
      "Epoch [461/700], Train Loss: 491.9690, Val Loss: 499.7311\n",
      "Epoch [462/700], Train Loss: 506.3193, Val Loss: 494.7480\n",
      "Epoch [463/700], Train Loss: 483.3475, Val Loss: 491.7181\n",
      "Epoch [464/700], Train Loss: 485.0491, Val Loss: 507.5168\n",
      "Epoch [465/700], Train Loss: 493.1587, Val Loss: 513.0173\n",
      "Epoch [466/700], Train Loss: 485.2451, Val Loss: 496.1424\n",
      "Epoch [467/700], Train Loss: 479.1082, Val Loss: 507.0243\n",
      "Epoch [468/700], Train Loss: 486.7170, Val Loss: 493.5293\n",
      "Epoch [469/700], Train Loss: 485.6112, Val Loss: 485.4012\n",
      "Epoch [470/700], Train Loss: 482.9860, Val Loss: 505.8925\n",
      "Epoch [471/700], Train Loss: 479.0127, Val Loss: 493.9085\n",
      "Epoch [472/700], Train Loss: 481.2408, Val Loss: 481.5838\n",
      "Epoch [473/700], Train Loss: 474.2679, Val Loss: 542.9080\n",
      "Epoch [474/700], Train Loss: 483.4997, Val Loss: 488.5496\n",
      "Epoch [475/700], Train Loss: 471.7858, Val Loss: 505.1925\n",
      "Epoch [476/700], Train Loss: 481.6113, Val Loss: 479.0240\n",
      "Epoch [477/700], Train Loss: 464.5594, Val Loss: 478.2136\n",
      "Epoch [478/700], Train Loss: 466.5213, Val Loss: 486.9429\n",
      "Epoch [479/700], Train Loss: 468.6229, Val Loss: 488.8366\n",
      "Epoch [480/700], Train Loss: 477.2842, Val Loss: 481.0498\n",
      "Epoch [481/700], Train Loss: 466.0225, Val Loss: 474.0533\n",
      "Epoch [482/700], Train Loss: 467.3044, Val Loss: 470.0053\n",
      "Epoch [483/700], Train Loss: 469.4452, Val Loss: 504.6796\n",
      "Epoch [484/700], Train Loss: 458.3737, Val Loss: 471.3056\n",
      "Epoch [485/700], Train Loss: 460.2784, Val Loss: 466.0344\n",
      "Epoch [486/700], Train Loss: 462.8440, Val Loss: 464.8294\n",
      "Epoch [487/700], Train Loss: 463.9338, Val Loss: 467.4401\n",
      "Epoch [488/700], Train Loss: 460.8079, Val Loss: 486.5036\n",
      "Epoch [489/700], Train Loss: 453.5693, Val Loss: 465.2801\n",
      "Epoch [490/700], Train Loss: 455.5548, Val Loss: 468.3098\n",
      "Epoch [491/700], Train Loss: 455.2990, Val Loss: 471.4762\n",
      "Epoch [492/700], Train Loss: 449.6258, Val Loss: 461.8995\n",
      "Epoch [493/700], Train Loss: 449.5584, Val Loss: 458.2155\n",
      "Epoch [494/700], Train Loss: 460.9479, Val Loss: 468.2666\n",
      "Epoch [495/700], Train Loss: 448.2069, Val Loss: 480.8848\n",
      "Epoch [496/700], Train Loss: 455.6887, Val Loss: 456.4854\n",
      "Epoch [497/700], Train Loss: 449.7206, Val Loss: 452.0441\n",
      "Epoch [498/700], Train Loss: 446.9957, Val Loss: 477.1935\n",
      "Epoch [499/700], Train Loss: 443.7019, Val Loss: 460.2992\n",
      "Epoch [500/700], Train Loss: 443.1566, Val Loss: 450.0182\n",
      "Epoch [501/700], Train Loss: 441.4132, Val Loss: 448.4472\n",
      "Epoch [502/700], Train Loss: 445.0871, Val Loss: 462.8508\n",
      "Epoch [503/700], Train Loss: 451.1275, Val Loss: 452.0112\n",
      "Epoch [504/700], Train Loss: 437.1548, Val Loss: 447.4397\n",
      "Epoch [505/700], Train Loss: 440.5148, Val Loss: 487.2855\n",
      "Epoch [506/700], Train Loss: 436.9606, Val Loss: 518.1054\n",
      "Epoch [507/700], Train Loss: 436.5100, Val Loss: 454.0009\n",
      "Epoch [508/700], Train Loss: 439.8419, Val Loss: 447.9126\n",
      "Epoch [509/700], Train Loss: 438.6743, Val Loss: 444.4954\n",
      "Epoch [510/700], Train Loss: 434.8159, Val Loss: 456.4689\n",
      "Epoch [511/700], Train Loss: 441.8251, Val Loss: 465.0979\n",
      "Epoch [512/700], Train Loss: 426.8442, Val Loss: 472.1699\n",
      "Epoch [513/700], Train Loss: 426.9583, Val Loss: 441.0939\n",
      "Epoch [514/700], Train Loss: 430.6993, Val Loss: 511.0998\n",
      "Epoch [515/700], Train Loss: 440.2643, Val Loss: 444.6186\n",
      "Epoch [516/700], Train Loss: 428.2901, Val Loss: 450.5462\n",
      "Epoch [517/700], Train Loss: 424.8083, Val Loss: 434.3155\n",
      "Epoch [518/700], Train Loss: 424.4679, Val Loss: 436.6753\n",
      "Epoch [519/700], Train Loss: 429.0469, Val Loss: 433.1363\n",
      "Epoch [520/700], Train Loss: 422.9583, Val Loss: 575.9052\n",
      "Epoch [521/700], Train Loss: 435.6618, Val Loss: 460.3749\n",
      "Epoch [522/700], Train Loss: 432.9950, Val Loss: 434.0851\n",
      "Epoch [523/700], Train Loss: 425.0791, Val Loss: 447.4252\n",
      "Epoch [524/700], Train Loss: 417.6641, Val Loss: 426.1592\n",
      "Epoch [525/700], Train Loss: 431.0506, Val Loss: 436.3706\n",
      "Epoch [526/700], Train Loss: 415.1871, Val Loss: 456.6199\n",
      "Epoch [527/700], Train Loss: 418.0813, Val Loss: 430.2401\n",
      "Epoch [528/700], Train Loss: 419.6662, Val Loss: 431.6767\n",
      "Epoch [529/700], Train Loss: 417.5905, Val Loss: 440.5496\n",
      "Epoch [530/700], Train Loss: 418.7101, Val Loss: 428.2569\n",
      "Epoch [531/700], Train Loss: 418.9791, Val Loss: 428.7472\n",
      "Epoch [532/700], Train Loss: 411.3941, Val Loss: 431.1448\n",
      "Epoch [533/700], Train Loss: 423.2355, Val Loss: 446.1719\n",
      "Epoch [534/700], Train Loss: 424.4952, Val Loss: 446.0275\n",
      "Epoch [535/700], Train Loss: 409.8723, Val Loss: 418.9367\n",
      "Epoch [536/700], Train Loss: 410.4157, Val Loss: 433.3669\n",
      "Epoch [537/700], Train Loss: 409.9897, Val Loss: 423.0927\n",
      "Epoch [538/700], Train Loss: 413.5807, Val Loss: 445.8257\n",
      "Epoch [539/700], Train Loss: 420.1046, Val Loss: 437.0199\n",
      "Epoch [540/700], Train Loss: 407.2020, Val Loss: 415.6739\n",
      "Epoch [541/700], Train Loss: 406.4942, Val Loss: 421.6796\n",
      "Epoch [542/700], Train Loss: 418.8213, Val Loss: 445.9653\n",
      "Epoch [543/700], Train Loss: 412.4641, Val Loss: 435.7683\n",
      "Epoch [544/700], Train Loss: 410.7333, Val Loss: 415.9649\n",
      "Epoch [545/700], Train Loss: 411.4749, Val Loss: 438.7377\n",
      "Epoch [546/700], Train Loss: 404.9232, Val Loss: 409.6345\n",
      "Epoch [547/700], Train Loss: 406.0636, Val Loss: 434.9742\n",
      "Epoch [548/700], Train Loss: 403.3548, Val Loss: 435.4701\n",
      "Epoch [549/700], Train Loss: 420.5846, Val Loss: 480.1681\n",
      "Epoch [550/700], Train Loss: 409.5388, Val Loss: 409.1099\n",
      "Epoch [551/700], Train Loss: 398.6723, Val Loss: 409.2363\n",
      "Epoch [552/700], Train Loss: 406.5032, Val Loss: 412.5821\n",
      "Epoch [553/700], Train Loss: 399.5519, Val Loss: 483.6875\n",
      "Epoch [554/700], Train Loss: 422.1132, Val Loss: 406.7810\n",
      "Epoch [555/700], Train Loss: 390.8703, Val Loss: 404.3205\n",
      "Epoch [556/700], Train Loss: 395.4080, Val Loss: 401.8042\n",
      "Epoch [557/700], Train Loss: 390.6868, Val Loss: 423.1656\n",
      "Epoch [558/700], Train Loss: 401.2271, Val Loss: 408.3907\n",
      "Epoch [559/700], Train Loss: 395.3337, Val Loss: 412.0479\n",
      "Epoch [560/700], Train Loss: 395.8652, Val Loss: 401.4364\n",
      "Epoch [561/700], Train Loss: 392.4993, Val Loss: 409.2447\n",
      "Epoch [562/700], Train Loss: 389.8291, Val Loss: 404.6226\n",
      "Epoch [563/700], Train Loss: 389.9287, Val Loss: 412.6795\n",
      "Epoch [564/700], Train Loss: 392.4839, Val Loss: 395.6217\n",
      "Epoch [565/700], Train Loss: 387.8998, Val Loss: 404.5041\n",
      "Epoch [566/700], Train Loss: 388.1726, Val Loss: 401.3893\n",
      "Epoch [567/700], Train Loss: 390.3013, Val Loss: 403.6468\n",
      "Epoch [568/700], Train Loss: 392.6967, Val Loss: 396.8903\n",
      "Epoch [569/700], Train Loss: 385.1801, Val Loss: 404.5781\n",
      "Epoch [570/700], Train Loss: 385.9638, Val Loss: 392.2759\n",
      "Epoch [571/700], Train Loss: 389.5184, Val Loss: 401.3496\n",
      "Epoch [572/700], Train Loss: 387.0143, Val Loss: 394.5505\n",
      "Epoch [573/700], Train Loss: 382.7686, Val Loss: 396.8836\n",
      "Epoch [574/700], Train Loss: 394.1955, Val Loss: 397.0736\n",
      "Epoch [575/700], Train Loss: 384.6462, Val Loss: 389.3114\n",
      "Epoch [576/700], Train Loss: 385.4856, Val Loss: 389.2715\n",
      "Epoch [577/700], Train Loss: 381.1284, Val Loss: 390.0499\n",
      "Epoch [578/700], Train Loss: 393.4763, Val Loss: 423.0531\n",
      "Epoch [579/700], Train Loss: 383.7609, Val Loss: 386.0943\n",
      "Epoch [580/700], Train Loss: 374.8282, Val Loss: 390.9088\n",
      "Epoch [581/700], Train Loss: 373.5485, Val Loss: 391.5888\n",
      "Epoch [582/700], Train Loss: 379.3823, Val Loss: 386.9738\n",
      "Epoch [583/700], Train Loss: 382.9698, Val Loss: 383.7544\n",
      "Epoch [584/700], Train Loss: 399.3652, Val Loss: 388.1124\n",
      "Epoch [585/700], Train Loss: 374.7310, Val Loss: 409.1480\n",
      "Epoch [586/700], Train Loss: 372.7078, Val Loss: 378.6783\n",
      "Epoch [587/700], Train Loss: 377.4340, Val Loss: 379.6327\n",
      "Epoch [588/700], Train Loss: 371.8161, Val Loss: 414.9292\n",
      "Epoch [589/700], Train Loss: 379.3945, Val Loss: 389.1169\n",
      "Epoch [590/700], Train Loss: 378.0586, Val Loss: 387.8878\n",
      "Epoch [591/700], Train Loss: 375.0425, Val Loss: 412.3400\n",
      "Epoch [592/700], Train Loss: 370.3257, Val Loss: 397.6792\n",
      "Epoch [593/700], Train Loss: 372.1680, Val Loss: 379.2762\n",
      "Epoch [594/700], Train Loss: 368.8883, Val Loss: 380.6603\n",
      "Epoch [595/700], Train Loss: 375.3163, Val Loss: 403.0095\n",
      "Epoch [596/700], Train Loss: 373.7976, Val Loss: 377.2706\n",
      "Epoch [597/700], Train Loss: 376.4105, Val Loss: 396.7700\n",
      "Epoch [598/700], Train Loss: 368.1569, Val Loss: 378.6345\n",
      "Epoch [599/700], Train Loss: 365.6338, Val Loss: 373.2759\n",
      "Epoch [600/700], Train Loss: 362.3216, Val Loss: 377.5152\n",
      "Epoch [601/700], Train Loss: 364.7799, Val Loss: 427.0383\n",
      "Epoch [602/700], Train Loss: 376.3063, Val Loss: 430.4873\n",
      "Epoch [603/700], Train Loss: 365.5139, Val Loss: 369.0816\n",
      "Epoch [604/700], Train Loss: 361.7480, Val Loss: 404.8789\n",
      "Epoch [605/700], Train Loss: 371.5839, Val Loss: 369.8069\n",
      "Epoch [606/700], Train Loss: 360.6710, Val Loss: 368.2791\n",
      "Epoch [607/700], Train Loss: 359.5273, Val Loss: 369.7341\n",
      "Epoch [608/700], Train Loss: 362.5173, Val Loss: 449.7866\n",
      "Epoch [609/700], Train Loss: 370.0944, Val Loss: 368.3163\n",
      "Epoch [610/700], Train Loss: 356.0250, Val Loss: 367.0586\n",
      "Epoch [611/700], Train Loss: 356.6197, Val Loss: 365.3015\n",
      "Epoch [612/700], Train Loss: 359.7642, Val Loss: 373.4048\n",
      "Epoch [613/700], Train Loss: 360.0367, Val Loss: 391.2271\n",
      "Epoch [614/700], Train Loss: 372.6468, Val Loss: 425.5614\n",
      "Epoch [615/700], Train Loss: 366.4993, Val Loss: 371.6105\n",
      "Epoch [616/700], Train Loss: 359.4812, Val Loss: 361.7091\n",
      "Epoch [617/700], Train Loss: 357.6455, Val Loss: 368.0005\n",
      "Epoch [618/700], Train Loss: 360.6487, Val Loss: 364.0094\n",
      "Epoch [619/700], Train Loss: 361.6667, Val Loss: 375.9019\n",
      "Epoch [620/700], Train Loss: 364.7897, Val Loss: 396.9169\n",
      "Epoch [621/700], Train Loss: 366.6815, Val Loss: 362.5481\n",
      "Epoch [622/700], Train Loss: 353.1266, Val Loss: 359.5807\n",
      "Epoch [623/700], Train Loss: 352.1839, Val Loss: 379.1072\n",
      "Epoch [624/700], Train Loss: 354.9423, Val Loss: 380.8954\n",
      "Epoch [625/700], Train Loss: 350.4688, Val Loss: 358.7910\n",
      "Epoch [626/700], Train Loss: 353.2714, Val Loss: 366.8850\n",
      "Epoch [627/700], Train Loss: 349.2066, Val Loss: 364.6823\n",
      "Epoch [628/700], Train Loss: 350.9111, Val Loss: 410.3250\n",
      "Epoch [629/700], Train Loss: 351.8641, Val Loss: 362.8738\n",
      "Epoch [630/700], Train Loss: 346.2962, Val Loss: 355.1507\n",
      "Epoch [631/700], Train Loss: 362.0276, Val Loss: 420.7473\n",
      "Epoch [632/700], Train Loss: 346.9710, Val Loss: 397.7506\n",
      "Epoch [633/700], Train Loss: 351.8696, Val Loss: 358.9054\n",
      "Epoch [634/700], Train Loss: 343.2374, Val Loss: 362.5416\n",
      "Epoch [635/700], Train Loss: 356.5164, Val Loss: 353.4658\n",
      "Epoch [636/700], Train Loss: 345.2925, Val Loss: 355.7399\n",
      "Epoch [637/700], Train Loss: 346.0401, Val Loss: 349.3281\n",
      "Epoch [638/700], Train Loss: 349.9529, Val Loss: 350.0690\n",
      "Epoch [639/700], Train Loss: 352.9602, Val Loss: 400.9024\n",
      "Epoch [640/700], Train Loss: 346.6770, Val Loss: 348.8537\n",
      "Epoch [641/700], Train Loss: 346.8807, Val Loss: 352.8712\n",
      "Epoch [642/700], Train Loss: 346.2079, Val Loss: 349.9713\n",
      "Epoch [643/700], Train Loss: 342.0985, Val Loss: 344.9766\n",
      "Epoch [644/700], Train Loss: 338.3932, Val Loss: 345.1953\n",
      "Epoch [645/700], Train Loss: 345.5661, Val Loss: 343.6019\n",
      "Epoch [646/700], Train Loss: 337.5159, Val Loss: 347.8604\n",
      "Epoch [647/700], Train Loss: 345.1502, Val Loss: 344.7538\n",
      "Epoch [648/700], Train Loss: 335.3234, Val Loss: 342.0756\n",
      "Epoch [649/700], Train Loss: 336.7008, Val Loss: 347.0589\n",
      "Epoch [650/700], Train Loss: 346.9747, Val Loss: 373.2043\n",
      "Epoch [651/700], Train Loss: 337.5501, Val Loss: 341.9060\n",
      "Epoch [652/700], Train Loss: 333.8932, Val Loss: 341.7935\n",
      "Epoch [653/700], Train Loss: 330.4889, Val Loss: 352.1142\n",
      "Epoch [654/700], Train Loss: 348.8088, Val Loss: 407.5091\n",
      "Epoch [655/700], Train Loss: 344.8204, Val Loss: 340.1167\n",
      "Epoch [656/700], Train Loss: 344.3466, Val Loss: 572.8550\n",
      "Epoch [657/700], Train Loss: 351.8614, Val Loss: 341.8639\n",
      "Epoch [658/700], Train Loss: 343.0512, Val Loss: 363.8284\n",
      "Epoch [659/700], Train Loss: 329.3139, Val Loss: 335.8704\n",
      "Epoch [660/700], Train Loss: 340.4847, Val Loss: 337.5226\n",
      "Epoch [661/700], Train Loss: 328.2074, Val Loss: 334.9235\n",
      "Epoch [662/700], Train Loss: 335.2710, Val Loss: 368.1159\n",
      "Epoch [663/700], Train Loss: 339.5505, Val Loss: 346.9361\n",
      "Epoch [664/700], Train Loss: 341.6961, Val Loss: 338.9720\n",
      "Epoch [665/700], Train Loss: 330.7459, Val Loss: 337.6733\n",
      "Epoch [666/700], Train Loss: 328.1025, Val Loss: 348.5607\n",
      "Epoch [667/700], Train Loss: 325.9439, Val Loss: 364.9656\n",
      "Epoch [668/700], Train Loss: 336.9770, Val Loss: 331.5422\n",
      "Epoch [669/700], Train Loss: 326.9915, Val Loss: 365.3758\n",
      "Epoch [670/700], Train Loss: 324.7334, Val Loss: 336.3431\n",
      "Epoch [671/700], Train Loss: 329.6334, Val Loss: 367.4282\n",
      "Epoch [672/700], Train Loss: 332.5296, Val Loss: 329.0602\n",
      "Epoch [673/700], Train Loss: 323.1025, Val Loss: 344.2760\n",
      "Epoch [674/700], Train Loss: 323.4544, Val Loss: 341.7316\n",
      "Epoch [675/700], Train Loss: 321.9244, Val Loss: 336.0808\n",
      "Epoch [676/700], Train Loss: 334.0707, Val Loss: 337.0856\n",
      "Epoch [677/700], Train Loss: 340.0490, Val Loss: 342.3124\n",
      "Epoch [678/700], Train Loss: 318.6654, Val Loss: 330.6083\n",
      "Epoch [679/700], Train Loss: 322.4439, Val Loss: 324.4281\n",
      "Epoch [680/700], Train Loss: 320.2553, Val Loss: 366.7118\n",
      "Epoch [681/700], Train Loss: 330.8283, Val Loss: 327.3637\n",
      "Epoch [682/700], Train Loss: 317.4275, Val Loss: 341.0586\n",
      "Epoch [683/700], Train Loss: 323.5990, Val Loss: 343.1870\n",
      "Epoch [684/700], Train Loss: 322.1681, Val Loss: 324.0337\n",
      "Epoch [685/700], Train Loss: 317.1643, Val Loss: 320.1567\n",
      "Epoch [686/700], Train Loss: 319.1589, Val Loss: 322.9885\n",
      "Epoch [687/700], Train Loss: 324.4785, Val Loss: 355.2052\n",
      "Epoch [688/700], Train Loss: 322.5896, Val Loss: 325.4445\n",
      "Epoch [689/700], Train Loss: 314.0972, Val Loss: 337.1096\n",
      "Epoch [690/700], Train Loss: 322.7538, Val Loss: 342.3119\n",
      "Epoch [691/700], Train Loss: 315.6451, Val Loss: 322.9221\n",
      "Epoch [692/700], Train Loss: 314.9553, Val Loss: 318.0011\n",
      "Epoch [693/700], Train Loss: 322.2165, Val Loss: 321.3037\n",
      "Epoch [694/700], Train Loss: 319.6302, Val Loss: 324.0918\n",
      "Epoch [695/700], Train Loss: 311.7616, Val Loss: 320.7247\n",
      "Epoch [696/700], Train Loss: 316.5610, Val Loss: 333.6050\n",
      "Epoch [697/700], Train Loss: 314.2642, Val Loss: 314.6250\n",
      "Epoch [698/700], Train Loss: 316.8174, Val Loss: 317.0056\n",
      "Epoch [699/700], Train Loss: 319.0148, Val Loss: 340.5920\n",
      "Epoch [700/700], Train Loss: 319.3122, Val Loss: 319.0918\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "314.6250351019965"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 9.874339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.874338655090332"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.tester(Xte,Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
